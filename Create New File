{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c06e95",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:14.056123Z",
     "iopub.status.busy": "2024-09-20T06:47:14.055233Z",
     "iopub.status.idle": "2024-09-20T06:47:14.536330Z",
     "shell.execute_reply": "2024-09-20T06:47:14.534657Z"
    },
    "papermill": {
     "duration": 0.499863,
     "end_time": "2024-09-20T06:47:14.539927",
     "exception": false,
     "start_time": "2024-09-20T06:47:14.040064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ga-xgb-xgb/train_pp.csv\n",
      "/kaggle/input/ga-xgb-xgb/Xt-2.csv\n",
      "/kaggle/input/ga-xgb-xgb/xgboost_protein_classifier-3.pkl\n",
      "/kaggle/input/ga-xgb-xgb/pp_testing_data.csv\n",
      "/kaggle/input/ga-xgb-xgb/test_model.fasta\n",
      "/kaggle/input/ga-xgb-xgb/X-3.csv\n",
      "/kaggle/input/ga-xgb-xgb/test_pp.csv\n",
      "/kaggle/input/ga-xgb-xgb/selected_feature_names.pkl\n",
      "/kaggle/input/ga-xgb-xgb/pp_training_data.csv\n",
      "/kaggle/input/ga-xgb-xgb/pp_for_ga.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee9e2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:14.560917Z",
     "iopub.status.busy": "2024-09-20T06:47:14.560320Z",
     "iopub.status.idle": "2024-09-20T06:47:16.054864Z",
     "shell.execute_reply": "2024-09-20T06:47:16.053518Z"
    },
    "papermill": {
     "duration": 1.508128,
     "end_time": "2024-09-20T06:47:16.057754",
     "exception": false,
     "start_time": "2024-09-20T06:47:14.549626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package Downloading\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re, os, sys\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9101756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.078451Z",
     "iopub.status.busy": "2024-09-20T06:47:16.077824Z",
     "iopub.status.idle": "2024-09-20T06:47:16.089381Z",
     "shell.execute_reply": "2024-09-20T06:47:16.088139Z"
    },
    "papermill": {
     "duration": 0.024864,
     "end_time": "2024-09-20T06:47:16.091932",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.067068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Seq reading\n",
    "def read_protein_sequences(file):\n",
    "    if os.path.exists(file) == False:\n",
    "        print('Error: file %s does not exist.' % file)\n",
    "        sys.exit(1)\n",
    "    with open(file,  errors='ignore') as f:\n",
    "        records = f.read()\n",
    "    if re.search('>', records) == None:\n",
    "        print('Error: the input file %s seems not in FASTA format!' % file)\n",
    "        sys.exit(1)\n",
    "    records = records.split('>')[1:]\n",
    "    fasta_sequences = []\n",
    "    for fasta in records:\n",
    "        array = fasta.split('\\n')\n",
    "        header, sequence = array[0].split()[0], re.sub('[^ACDEFGHIKLMNPQRSTVWY-]', '', ''.join(array[1:]).upper())\n",
    "        header_array = header.split('|')\n",
    "        name = header_array[0]\n",
    "        #label = 'None' #header_array[1] if len(header_array) >= 1 else '0'\n",
    "        #label_train = 'None' #header_array[2] if len(header_array) >= 2 else 'training'\n",
    "        fasta_sequences.append([name, sequence])\n",
    "    return fasta_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f735a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.116664Z",
     "iopub.status.busy": "2024-09-20T06:47:16.116215Z",
     "iopub.status.idle": "2024-09-20T06:47:16.391700Z",
     "shell.execute_reply": "2024-09-20T06:47:16.390275Z"
    },
    "papermill": {
     "duration": 0.29376,
     "end_time": "2024-09-20T06:47:16.394896",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.101136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def AAC(fastas, **kw):\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    #AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for i in AA:\n",
    "        header.append(i)\n",
    "    #encodings.append(header)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        count = Counter(sequence)\n",
    "        for key in count:\n",
    "            count[key] = count[key]/len(sequence)\n",
    "        code = []\n",
    "        for aa in AA:\n",
    "            code.append(count[aa])\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "\n",
    "def AAINDEX(fastas, props=None, **kw):\n",
    "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    AAIN = 'ANDN920101$ARGP820101$ARGP820102$ARGP820103$BEGF750101$BEGF750102$BEGF750103$BHAR880101$BIGC670101$BIOV880101$BIOV880102$BROC820101$BROC820102$BULH740101$BULH740102$BUNA790101$BUNA790102$BUNA790103$BURA740101$BURA740102$CHAM810101$CHAM820101$CHAM820102$CHAM830101$CHAM830102$CHAM830103$CHAM830104$CHAM830105$CHAM830106$CHAM830107$CHAM830108$CHOC750101$CHOC760101$CHOC760102$CHOC760103$CHOC760104$CHOP780101$CHOP780201$CHOP780202$CHOP780203$CHOP780204$CHOP780205$CHOP780206$CHOP780207$CHOP780208$CHOP780209$CHOP780210$CHOP780211$CHOP780212$CHOP780213$CHOP780214$CHOP780215$CHOP780216$CIDH920101$CIDH920102$CIDH920103$CIDH920104$CIDH920105$COHE430101$CRAJ730101$CRAJ730102$CRAJ730103$DAWD720101$DAYM780101$DAYM780201$DESM900101$DESM900102$EISD840101$EISD860101$EISD860102$EISD860103$FASG760101$FASG760102$FASG760103$FASG760104$FASG760105$FAUJ830101$FAUJ880101$FAUJ880102$FAUJ880103$FAUJ880104$FAUJ880105$FAUJ880106$FAUJ880107$FAUJ880108$FAUJ880109$FAUJ880110$FAUJ880111$FAUJ880112$FAUJ880113$FINA770101$FINA910101$FINA910102$FINA910103$FINA910104$GARJ730101$GEIM800101$GEIM800102$GEIM800103$GEIM800104$GEIM800105$GEIM800106$GEIM800107$GEIM800108$GEIM800109$GEIM800110$GEIM800111$GOLD730101$GOLD730102$GRAR740101$GRAR740102$GRAR740103$GUYH850101$HOPA770101$HOPT810101$HUTJ700101$HUTJ700102$HUTJ700103$ISOY800101$ISOY800102$ISOY800103$ISOY800104$ISOY800105$ISOY800106$ISOY800107$ISOY800108$JANJ780101$JANJ780102$JANJ780103$JANJ790101$JANJ790102$JOND750101$JOND750102$JOND920101$JOND920102$JUKT750101$JUNJ780101$KANM800101$KANM800102$KANM800103$KANM800104$KARP850101$KARP850102$KARP850103$KHAG800101$KLEP840101$KRIW710101$KRIW790101$KRIW790102$KRIW790103$KYTJ820101$LAWE840101$LEVM760101$LEVM760102$LEVM760103$LEVM760104$LEVM760105$LEVM760106$LEVM760107$LEVM780101$LEVM780102$LEVM780103$LEVM780104$LEVM780105$LEVM780106$LEWP710101$LIFS790101$LIFS790102$LIFS790103$MANP780101$MAXF760101$MAXF760102$MAXF760103$MAXF760104$MAXF760105$MAXF760106$MCMT640101$MEEJ800101$MEEJ800102$MEEJ810101$MEEJ810102$MEIH800101$MEIH800102$MEIH800103$MIYS850101$NAGK730101$NAGK730102$NAGK730103$NAKH900101$NAKH900102$NAKH900103$NAKH900104$NAKH900105$NAKH900106$NAKH900107$NAKH900108$NAKH900109$NAKH900110$NAKH900111$NAKH900112$NAKH900113$NAKH920101$NAKH920102$NAKH920103$NAKH920104$NAKH920105$NAKH920106$NAKH920107$NAKH920108$NISK800101$NISK860101$NOZY710101$OOBM770101$OOBM770102$OOBM770103$OOBM770104$OOBM770105$OOBM850101$OOBM850102$OOBM850103$OOBM850104$OOBM850105$PALJ810101$PALJ810102$PALJ810103$PALJ810104$PALJ810105$PALJ810106$PALJ810107$PALJ810108$PALJ810109$PALJ810110$PALJ810111$PALJ810112$PALJ810113$PALJ810114$PALJ810115$PALJ810116$PARJ860101$PLIV810101$PONP800101$PONP800102$PONP800103$PONP800104$PONP800105$PONP800106$PONP800107$PONP800108$PRAM820101$PRAM820102$PRAM820103$PRAM900101$PRAM900102$PRAM900103$PRAM900104$PTIO830101$PTIO830102$QIAN880101$QIAN880102$QIAN880103$QIAN880104$QIAN880105$QIAN880106$QIAN880107$QIAN880108$QIAN880109$QIAN880110$QIAN880111$QIAN880112$QIAN880113$QIAN880114$QIAN880115$QIAN880116$QIAN880117$QIAN880118$QIAN880119$QIAN880120$QIAN880121$QIAN880122$QIAN880123$QIAN880124$QIAN880125$QIAN880126$QIAN880127$QIAN880128$QIAN880129$QIAN880130$QIAN880131$QIAN880132$QIAN880133$QIAN880134$QIAN880135$QIAN880136$QIAN880137$QIAN880138$QIAN880139$RACS770101$RACS770102$RACS770103$RACS820101$RACS820102$RACS820103$RACS820104$RACS820105$RACS820106$RACS820107$RACS820108$RACS820109$RACS820110$RACS820111$RACS820112$RACS820113$RACS820114$RADA880101$RADA880102$RADA880103$RADA880104$RADA880105$RADA880106$RADA880107$RADA880108$RICJ880101$RICJ880102$RICJ880103$RICJ880104$RICJ880105$RICJ880106$RICJ880107$RICJ880108$RICJ880109$RICJ880110$RICJ880111$RICJ880112$RICJ880113$RICJ880114$RICJ880115$RICJ880116$RICJ880117$ROBB760101$ROBB760102$ROBB760103$ROBB760104$ROBB760105$ROBB760106$ROBB760107$ROBB760108$ROBB760109$ROBB760110$ROBB760111$ROBB760112$ROBB760113$ROBB790101$ROSG850101$ROSG850102$ROSM880101$ROSM880102$ROSM880103$SIMZ760101$SNEP660101$SNEP660102$SNEP660103$SNEP660104$SUEM840101$SUEM840102$SWER830101$TANS770101$TANS770102$TANS770103$TANS770104$TANS770105$TANS770106$TANS770107$TANS770108$TANS770109$TANS770110$VASM830101$VASM830102$VASM830103$VELV850101$VENT840101$VHEG790101$WARP780101$WEBA780101$WERD780101$WERD780102$WERD780103$WERD780104$WOEC730101$WOLR810101$WOLS870101$WOLS870102$WOLS870103$YUTK870101$YUTK870102$YUTK870103$YUTK870104$ZASB820101$ZIMJ680101$ZIMJ680102$ZIMJ680103$ZIMJ680104$ZIMJ680105$AURR980101$AURR980102$AURR980103$AURR980104$AURR980105$AURR980106$AURR980107$AURR980108$AURR980109$AURR980110$AURR980111$AURR980112$AURR980113$AURR980114$AURR980115$AURR980116$AURR980117$AURR980118$AURR980119$AURR980120$ONEK900101$ONEK900102$VINM940101$VINM940102$VINM940103$VINM940104$MUNV940101$MUNV940102$MUNV940103$MUNV940104$MUNV940105$WIMW960101$KIMC930101$MONM990101$BLAM930101$PARS000101$PARS000102$KUMS000101$KUMS000102$KUMS000103$KUMS000104$TAKK010101$FODM020101$NADH010101$NADH010102$NADH010103$NADH010104$NADH010105$NADH010106$NADH010107$MONM990201$KOEP990101$KOEP990102$CEDJ970101$CEDJ970102$CEDJ970103$CEDJ970104$CEDJ970105$FUKS010101$FUKS010102$FUKS010103$FUKS010104$FUKS010105$FUKS010106$FUKS010107$FUKS010108$FUKS010109$FUKS010110$FUKS010111$FUKS010112$MITS020101$TSAJ990101$TSAJ990102$COSI940101$PONP930101$WILM950101$WILM950102$WILM950103$WILM950104$KUHL950101$GUOD860101$JURD980101$BASU050101$BASU050102$BASU050103$SUYM030101$PUNT030101$PUNT030102$GEOR030101$GEOR030102$GEOR030103$GEOR030104$GEOR030105$GEOR030106$GEOR030107$GEOR030108$GEOR030109$ZHOH040101$ZHOH040102$ZHOH040103$BAEK050101$HARY940101$PONJ960101$DIGM050101$WOLR790101$OLSK800101$KIDA850101$GUYH850102$GUYH850104$GUYH850105$JACR890101$COWR900101$BLAS910101$CASG920101$CORJ870101$CORJ870102$CORJ870103$CORJ870104$CORJ870105$CORJ870106$CORJ870107$CORJ870108$MIYS990101$MIYS990102$MIYS990103$MIYS990104$MIYS990105$ENGD860101$FASG890101'\n",
    "    AAID = '4.35|4.38|4.75|4.76|4.65|4.37|4.29|3.97|4.63|3.95|4.17|4.36|4.52|4.66|4.44|4.50|4.35|4.70|4.60|3.95$0.61|0.60|0.06|0.46|1.07|0.|0.47|0.07|0.61|2.22|1.53|1.15|1.18|2.02|1.95|0.05|0.05|2.65|1.88|1.32$1.18|0.20|0.23|0.05|1.89|0.72|0.11|0.49|0.31|1.45|3.23|0.06|2.67|1.96|0.76|0.97|0.84|0.77|0.39|1.08$1.56|0.45|0.27|0.14|1.23|0.51|0.23|0.62|0.29|1.67|2.93|0.15|2.96|2.03|0.76|0.81|0.91|1.08|0.68|1.14$1.|0.52|0.35|0.44|0.06|0.44|0.73|0.35|0.60|0.73|1.|0.60|1.|0.60|0.06|0.35|0.44|0.73|0.44|0.82$0.77|0.72|0.55|0.65|0.65|0.72|0.55|0.65|0.83|0.98|0.83|0.55|0.98|0.98|0.55|0.55|0.83|0.77|0.83|0.98$0.37|0.84|0.97|0.97|0.84|0.64|0.53|0.97|0.75|0.37|0.53|0.75|0.64|0.53|0.97|0.84|0.75|0.97|0.84|0.37$0.357|0.529|0.463|0.511|0.346|0.493|0.497|0.544|0.323|0.462|0.365|0.466|0.295|0.314|0.509|0.507|0.444|0.305|0.420|0.386$52.6|109.1|75.7|68.4|68.3|89.7|84.7|36.3|91.9|102.0|102.0|105.1|97.7|113.9|73.6|54.9|71.2|135.4|116.2|85.1$16.|-70.|-74.|-78.|168.|-73.|-106.|-13.|50.|151.|145.|-141.|124.|189.|-20.|-70.|-38.|145.|53.|123.$44.|-68.|-72.|-91.|90.|-117.|-139.|-8.|47.|100.|108.|-188.|121.|148.|-36.|-60.|-54.|163.|22.|117.$7.3|-3.6|-5.7|-2.9|-9.2|-0.3|-7.1|-1.2|-2.1|6.6|20.0|-3.7|5.6|19.2|5.1|-4.1|0.8|16.3|5.9|3.5$3.9|3.2|-2.8|-2.8|-14.3|1.8|-7.5|-2.3|2.0|11.0|15.0|-2.5|4.1|14.7|5.6|-3.5|1.1|17.8|3.8|2.1$-0.20|-0.12|0.08|-0.20|-0.45|0.16|-0.30|0.00|-0.12|-2.26|-2.46|-0.35|-1.47|-2.33|-0.98|-0.39|-0.52|-2.01|-2.24|-1.56$0.691|0.728|0.596|0.558|0.624|0.649|0.632|0.592|0.646|0.809|0.842|0.767|0.709|0.756|0.730|0.594|0.655|0.743|0.743|0.777$8.249|8.274|8.747|8.410|8.312|8.411|8.368|8.391|8.415|8.195|8.423|8.408|8.418|8.228|0.|8.380|8.236|8.094|8.183|8.436$4.349|4.396|4.755|4.765|4.686|4.373|4.295|3.972|4.630|4.224|4.385|4.358|4.513|4.663|4.471|4.498|4.346|4.702|4.604|4.184$6.5|6.9|7.5|7.0|7.7|6.0|7.0|5.6|8.0|7.0|6.5|6.5|0.|9.4|0.|6.5|6.9|0.|6.8|7.0$0.486|0.262|0.193|0.288|0.200|0.418|0.538|0.120|0.400|0.370|0.420|0.402|0.417|0.318|0.208|0.200|0.272|0.462|0.161|0.379$0.288|0.362|0.229|0.271|0.533|0.327|0.262|0.312|0.200|0.411|0.400|0.265|0.375|0.318|0.340|0.354|0.388|0.231|0.429|0.495$0.52|0.68|0.76|0.76|0.62|0.68|0.68|0.00|0.70|1.02|0.98|0.68|0.78|0.70|0.36|0.53|0.50|0.70|0.70|0.76$0.046|0.291|0.134|0.105|0.128|0.180|0.151|0.000|0.230|0.186|0.186|0.219|0.221|0.290|0.131|0.062|0.108|0.409|0.298|0.140$-0.368|-1.03|0.|2.06|4.53|0.731|1.77|-0.525|0.|0.791|1.07|0.|0.656|1.06|-2.24|-0.524|0.|1.60|4.91|0.401$0.71|1.06|1.37|1.21|1.19|0.87|0.84|1.52|1.07|0.66|0.69|0.99|0.59|0.71|1.61|1.34|1.08|0.76|1.07|0.63$-0.118|0.124|0.289|0.048|0.083|-0.105|-0.245|0.104|0.138|0.230|-0.052|0.032|-0.258|0.015|0.|0.225|0.166|0.158|0.094|0.513$0.|1.|1.|1.|1.|1.|1.|0.|1.|2.|1.|1.|1.|1.|0.|1.|2.|1.|1.|2.$0.|1.|1.|1.|0.|1.|1.|0.|1.|1.|2.|1.|1.|1.|0.|0.|0.|1.|1.|0.$0.|1.|0.|0.|0.|1.|1.|0.|1.|0.|0.|1.|1.|1.|0.|0.|0.|1.5|1.|0.$0.|5.|2.|2.|1.|3.|3.|0.|3.|2.|2.|4.|3.|4.|0.|1.|1.|5.|5.|1.$0.|0.|1.|1.|0.|0.|1.|1.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.$0.|1.|1.|0.|1.|1.|0.|0.|1.|0.|0.|1.|1.|1.|0.|0.|0.|1.|1.|0.$91.5|202.0|135.2|124.5|117.7|161.1|155.1|66.4|167.3|168.8|167.9|171.3|170.8|203.4|129.3|99.1|122.1|237.6|203.6|141.7$115.|225.|160.|150.|135.|180.|190.|75.|195.|175.|170.|200.|185.|210.|145.|115.|140.|255.|230.|155.$25.|90.|63.|50.|19.|71.|49.|23.|43.|18.|23.|97.|31.|24.|50.|44.|47.|32.|60.|18.$0.38|0.01|0.12|0.15|0.45|0.07|0.18|0.36|0.17|0.60|0.45|0.03|0.40|0.50|0.18|0.22|0.23|0.27|0.15|0.54$0.20|0.00|0.03|0.04|0.22|0.01|0.03|0.18|0.02|0.19|0.16|0.00|0.11|0.14|0.04|0.08|0.08|0.04|0.03|0.18$0.66|0.95|1.56|1.46|1.19|0.98|0.74|1.56|0.95|0.47|0.59|1.01|0.60|0.60|1.52|1.43|0.96|0.96|1.14|0.50$1.42|0.98|0.67|1.01|0.70|1.11|1.51|0.57|1.00|1.08|1.21|1.16|1.45|1.13|0.57|0.77|0.83|1.08|0.69|1.06$0.83|0.93|0.89|0.54|1.19|1.10|0.37|0.75|0.87|1.60|1.30|0.74|1.05|1.38|0.55|0.75|1.19|1.37|1.47|1.70$0.74|1.01|1.46|1.52|0.96|0.96|0.95|1.56|0.95|0.47|0.50|1.19|0.60|0.66|1.56|1.43|0.98|0.60|1.14|0.59$1.29|0.44|0.81|2.02|0.66|1.22|2.44|0.76|0.73|0.67|0.58|0.66|0.71|0.61|2.01|0.74|1.08|1.47|0.68|0.61$1.20|1.25|0.59|0.61|1.11|1.22|1.24|0.42|1.77|0.98|1.13|1.83|1.57|1.10|0.00|0.96|0.75|0.40|0.73|1.25$0.70|0.34|1.42|0.98|0.65|0.75|1.04|1.41|1.22|0.78|0.85|1.01|0.83|0.93|1.10|1.55|1.09|0.62|0.99|0.75$0.52|1.24|1.64|1.06|0.94|0.70|0.59|1.64|1.86|0.87|0.84|1.49|0.52|1.04|1.58|0.93|0.86|0.16|0.96|0.32$0.86|0.90|0.66|0.38|0.87|1.65|0.35|0.63|0.54|1.94|1.30|1.00|1.43|1.50|0.66|0.63|1.17|1.49|1.07|1.69$0.75|0.90|1.21|0.85|1.11|0.65|0.55|0.74|0.90|1.35|1.27|0.74|0.95|1.50|0.40|0.79|0.75|1.19|1.96|1.79$0.67|0.89|1.86|1.39|1.34|1.09|0.92|1.46|0.78|0.59|0.46|1.09|0.52|0.30|1.58|1.41|1.09|0.48|1.23|0.42$0.74|1.05|1.13|1.32|0.53|0.77|0.85|1.68|0.96|0.53|0.59|0.82|0.85|0.44|1.69|1.49|1.16|1.59|1.01|0.59$0.060|0.070|0.161|0.147|0.149|0.074|0.056|0.102|0.140|0.043|0.061|0.055|0.068|0.059|0.102|0.120|0.086|0.077|0.082|0.062$0.076|0.106|0.083|0.110|0.053|0.098|0.060|0.085|0.047|0.034|0.025|0.115|0.082|0.041|0.301|0.139|0.108|0.013|0.065|0.048$0.035|0.099|0.191|0.179|0.117|0.037|0.077|0.190|0.093|0.013|0.036|0.072|0.014|0.065|0.034|0.125|0.065|0.064|0.114|0.028$0.058|0.085|0.091|0.081|0.128|0.098|0.064|0.152|0.054|0.056|0.070|0.095|0.055|0.065|0.068|0.106|0.079|0.167|0.125|0.053$0.64|1.05|1.56|1.61|0.92|0.84|0.80|1.63|0.77|0.29|0.36|1.13|0.51|0.62|2.04|1.52|0.98|0.48|1.08|0.43$-0.45|-0.24|-0.20|-1.52|0.79|-0.99|-0.80|-1.00|1.07|0.76|1.29|-0.36|1.37|1.48|-0.12|-0.98|-0.70|1.38|1.49|1.26$-0.08|-0.09|-0.70|-0.71|0.76|-0.40|-1.31|-0.84|0.43|1.39|1.24|-0.09|1.27|1.53|-0.01|-0.93|-0.59|2.25|1.53|1.09$0.36|-0.52|-0.90|-1.09|0.70|-1.05|-0.83|-0.82|0.16|2.17|1.18|-0.56|1.21|1.01|-0.06|-0.60|-1.20|1.31|1.05|1.21$0.17|-0.70|-0.90|-1.05|1.24|-1.20|-1.19|-0.57|-0.25|2.06|0.96|-0.62|0.60|1.29|-0.21|-0.83|-0.62|1.51|0.66|1.21$0.02|-0.42|-0.77|-1.04|0.77|-1.10|-1.14|-0.80|0.26|1.81|1.14|-0.41|1.00|1.35|-0.09|-0.97|-0.77|1.71|1.11|1.13$0.75|0.70|0.61|0.60|0.61|0.67|0.66|0.64|0.67|0.90|0.90|0.82|0.75|0.77|0.76|0.68|0.70|0.74|0.71|0.86$1.33|0.79|0.72|0.97|0.93|1.42|1.66|0.58|1.49|0.99|1.29|1.03|1.40|1.15|0.49|0.83|0.94|1.33|0.49|0.96$1.00|0.74|0.75|0.89|0.99|0.87|0.37|0.56|0.36|1.75|1.53|1.18|1.40|1.26|0.36|0.65|1.15|0.84|1.41|1.61$0.60|0.79|1.42|1.24|1.29|0.92|0.64|1.38|0.95|0.67|0.70|1.10|0.67|1.05|1.47|1.26|1.05|1.23|1.35|0.48$2.5|7.5|5.0|2.5|3.0|6.0|5.0|0.5|6.0|5.5|5.5|7.0|6.0|6.5|5.5|3.0|5.0|7.0|7.0|5.0$8.6|4.9|4.3|5.5|2.9|3.9|6.0|8.4|2.0|4.5|7.4|6.6|1.7|3.6|5.2|7.0|6.1|1.3|3.4|6.6$100.|65.|134.|106.|20.|93.|102.|49.|66.|96.|40.|56.|94.|41.|56.|120.|97.|18.|41.|74.$1.56|0.59|0.51|0.23|1.80|0.39|0.19|1.03|1.|1.27|1.38|0.15|1.93|1.42|0.27|0.96|1.11|0.91|1.10|1.58$1.26|0.38|0.59|0.27|1.60|0.39|0.23|1.08|1.|1.44|1.36|0.33|1.52|1.46|0.54|0.98|1.01|1.06|0.89|1.33$0.25|-1.76|-0.64|-0.72|0.04|-0.69|-0.62|0.16|-0.40|0.73|0.53|-1.10|0.26|0.61|-0.07|-0.26|-0.18|0.37|0.02|0.54$0.67|-2.1|-0.6|-1.2|0.38|-0.22|-0.76|0.|0.64|1.9|1.9|-0.57|2.4|2.3|1.2|0.01|0.52|2.6|1.6|1.5$0.|10.|1.3|1.9|0.17|1.9|3.|0.|0.99|1.2|1.0|5.7|1.9|1.1|0.18|0.73|1.5|1.6|1.8|0.48$0.|-0.96|-0.86|-0.98|0.76|-1.0|-0.89|0.|-0.75|0.99|0.89|-0.99|0.94|0.92|0.22|-0.67|0.09|0.67|-0.93|0.84$89.09|174.20|132.12|133.10|121.15|146.15|147.13|75.07|155.16|131.17|131.17|146.19|149.21|165.19|115.13|105.09|119.12|204.24|181.19|117.15$297.|238.|236.|270.|178.|185.|249.|290.|277.|284.|337.|224.|283.|284.|222.|228.|253.|282.|344.|293.$1.80|12.50|-5.60|5.05|-16.50|6.30|12.00|0.00|-38.50|12.40|-11.00|14.60|-10.00|-34.50|-86.20|-7.50|-28.00|-33.70|-10.00|5.63$9.69|8.99|8.80|9.60|8.35|9.13|9.67|9.78|9.17|9.68|9.60|9.18|9.21|9.18|10.64|9.21|9.10|9.44|9.11|9.62$2.34|1.82|2.02|1.88|1.92|2.17|2.10|2.35|1.82|2.36|2.36|2.16|2.28|2.16|1.95|2.19|2.09|2.43|2.20|2.32$0.31|-1.01|-0.60|-0.77|1.54|-0.22|-0.64|0.00|0.13|1.80|1.70|-0.99|1.23|1.79|0.72|-0.04|0.26|2.25|0.96|1.22$1.28|2.34|1.60|1.60|1.77|1.56|1.56|0.00|2.99|4.19|2.59|1.89|2.35|2.94|2.67|1.31|3.03|3.21|2.94|3.67$0.53|0.69|0.58|0.59|0.66|0.71|0.72|0.00|0.64|0.96|0.92|0.78|0.77|0.71|0.|0.55|0.63|0.84|0.71|0.89$1.00|6.13|2.95|2.78|2.43|3.95|3.78|0.00|4.66|4.00|4.00|4.77|4.43|5.89|2.72|1.60|2.60|8.08|6.47|3.00$2.87|7.82|4.58|4.74|4.47|6.11|5.97|2.06|5.23|4.92|4.92|6.89|6.36|4.62|4.11|3.97|4.11|7.68|4.73|4.11$1.52|1.52|1.52|1.52|1.52|1.52|1.52|1.00|1.52|1.90|1.52|1.52|1.52|1.52|1.52|1.52|1.73|1.52|1.52|1.90$2.04|6.24|4.37|3.78|3.41|3.53|3.31|1.00|5.66|3.49|4.45|4.87|4.80|6.02|4.31|2.70|3.17|5.90|6.72|3.17$7.3|11.1|8.0|9.2|14.4|10.6|11.4|0.0|10.2|16.1|10.1|10.9|10.4|13.9|17.8|13.1|16.7|13.2|13.9|17.2$-0.01|0.04|0.06|0.15|0.12|0.05|0.07|0.00|0.08|-0.01|-0.01|0.00|0.04|0.03|0.|0.11|0.04|0.00|0.03|0.01$0.|4.|2.|1.|0.|2.|1.|0.|1.|0.|0.|2.|0.|0.|0.|1.|1.|1.|1.|0.$0.|3.|3.|4.|0.|3.|4.|0.|1.|0.|0.|1.|0.|0.|0.|2.|2.|0.|2.|0.$0.|1.|0.|0.|0.|0.|0.|0.|1.|0.|0.|1.|0.|0.|0.|0.|0.|0.|0.|0.$0.|0.|0.|1.|0.|0.|1.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.|0.$4.76|4.30|3.64|5.69|3.67|4.54|5.48|3.77|2.84|4.81|4.79|4.27|4.25|4.31|0.|3.83|3.87|4.75|4.30|4.86$1.08|1.05|0.85|0.85|0.95|0.95|1.15|0.55|1.00|1.05|1.25|1.15|1.15|1.10|0.71|0.75|0.75|1.10|1.10|0.95$1.|0.70|1.70|3.20|1.|1.|1.70|1.|1.|0.60|1.|0.70|1.|1.|1.|1.70|1.70|1.|1.|0.60$1.|0.70|1.|1.70|1.|1.|1.70|1.30|1.|1.|1.|0.70|1.|1.|13.|1.|1.|1.|1.|1.$1.20|1.70|1.20|0.70|1.|1.|0.70|0.80|1.20|0.80|1.|1.70|1.|1.|1.|1.50|1.|1.|1.|0.80$1.|1.70|1.|0.70|1.|1.|0.70|1.50|1.|1.|1.|1.70|1.|1.|0.10|1.|1.|1.|1.|1.$0.28|0.10|0.25|0.21|0.28|0.35|0.33|0.17|0.21|0.82|1.00|0.09|0.74|2.18|0.39|0.12|0.21|5.70|1.26|0.60$1.29|1.|0.81|1.10|0.79|1.07|1.49|0.63|1.33|1.05|1.31|1.33|1.54|1.13|0.63|0.78|0.77|1.18|0.71|0.81$1.13|1.09|1.06|0.94|1.32|0.93|1.20|0.83|1.09|1.05|1.13|1.08|1.23|1.01|0.82|1.01|1.17|1.32|0.88|1.13$1.55|0.20|1.20|1.55|1.44|1.13|1.67|0.59|1.21|1.27|1.25|1.20|1.37|0.40|0.21|1.01|0.55|1.86|1.08|0.64$1.19|1.|0.94|1.07|0.95|1.32|1.64|0.60|1.03|1.12|1.18|1.27|1.49|1.02|0.68|0.81|0.85|1.18|0.77|0.74$0.84|1.04|0.66|0.59|1.27|1.02|0.57|0.94|0.81|1.29|1.10|0.86|0.88|1.15|0.80|1.05|1.20|1.15|1.39|1.56$0.86|1.15|0.60|0.66|0.91|1.11|0.37|0.86|1.07|1.17|1.28|1.01|1.15|1.34|0.61|0.91|1.14|1.13|1.37|1.31$0.91|0.99|0.72|0.74|1.12|0.90|0.41|0.91|1.01|1.29|1.23|0.86|0.96|1.26|0.65|0.93|1.05|1.15|1.21|1.58$0.91|1.|1.64|1.40|0.93|0.94|0.97|1.51|0.90|0.65|0.59|0.82|0.58|0.72|1.66|1.23|1.04|0.67|0.92|0.60$0.80|0.96|1.10|1.60|0.|1.60|0.40|2.|0.96|0.85|0.80|0.94|0.39|1.20|2.10|1.30|0.60|0.|1.80|0.80$1.10|0.93|1.57|1.41|1.05|0.81|1.40|1.30|0.85|0.67|0.52|0.94|0.69|0.60|1.77|1.13|0.88|0.62|0.41|0.58$0.93|1.01|1.36|1.22|0.92|0.83|1.05|1.45|0.96|0.58|0.59|0.91|0.60|0.71|1.67|1.25|1.08|0.68|0.98|0.62$0.75|0.75|0.69|0.00|1.00|0.59|0.00|0.00|0.00|2.95|2.40|1.50|1.30|2.65|2.60|0.00|0.45|3.00|2.85|1.70$88.3|181.2|125.1|110.8|112.4|148.7|140.5|60.0|152.6|168.5|168.5|175.6|162.2|189.0|122.2|88.7|118.2|227.0|193.0|141.4$0.00|0.65|1.33|1.38|2.75|0.89|0.92|0.74|0.58|0.00|0.00|0.33|0.00|0.00|0.39|1.42|0.71|0.13|0.20|0.00$8.1|10.5|11.6|13.0|5.5|10.5|12.3|9.0|10.4|5.2|4.9|11.3|5.7|5.2|8.0|9.2|8.6|5.4|6.2|5.9$31.|124.|56.|54.|55.|85.|83.|3.|96.|111.|111.|119.|105.|132.|32.5|32.|61.|170.|136.|84.$0.10|1.91|0.48|0.78|-1.42|0.95|0.83|0.33|-0.50|-1.13|-1.18|1.40|-1.59|-2.12|0.73|0.52|0.07|-0.51|-0.21|-1.27$1.0|2.3|2.2|6.5|0.1|2.1|6.2|1.1|2.8|0.8|0.8|5.3|0.7|1.4|0.9|1.7|1.5|1.9|2.1|0.9$-0.5|3.0|0.2|3.0|-1.0|0.2|3.0|0.0|-0.5|-1.8|-1.8|3.0|-1.3|-2.5|0.0|0.3|-0.4|-3.4|-2.3|-1.5$29.22|26.37|38.30|37.09|50.70|44.02|41.84|23.71|59.64|45.00|48.03|57.10|69.32|48.52|36.13|32.40|35.20|56.92|51.73|40.35$30.88|68.43|41.70|40.66|53.83|46.62|44.98|24.74|65.99|49.71|50.62|63.21|55.32|51.06|39.21|35.65|36.50|60.00|51.15|42.75$154.33|341.01|207.90|194.91|219.79|235.51|223.16|127.90|242.54|233.21|232.30|300.46|202.65|204.74|179.93|174.06|205.80|237.01|229.15|207.60$1.53|1.17|0.60|1.00|0.89|1.27|1.63|0.44|1.03|1.07|1.32|1.26|1.66|1.22|0.25|0.65|0.86|1.05|0.70|0.93$0.86|0.98|0.74|0.69|1.39|0.89|0.66|0.70|1.06|1.31|1.01|0.77|1.06|1.16|1.16|1.09|1.24|1.17|1.28|1.40$0.78|1.06|1.56|1.50|0.60|0.78|0.97|1.73|0.83|0.40|0.57|1.01|0.30|0.67|1.55|1.19|1.09|0.74|1.14|0.44$1.09|0.97|1.14|0.77|0.50|0.83|0.92|1.25|0.67|0.66|0.44|1.25|0.45|0.50|2.96|1.21|1.33|0.62|0.94|0.56$0.35|0.75|2.12|2.16|0.50|0.73|0.65|2.40|1.19|0.12|0.58|0.83|0.22|0.89|0.43|1.24|0.85|0.62|1.44|0.43$1.09|1.07|0.88|1.24|1.04|1.09|1.14|0.27|1.07|0.97|1.30|1.20|0.55|0.80|1.78|1.20|0.99|1.03|0.69|0.77$1.34|2.78|0.92|1.77|1.44|0.79|2.54|0.95|0.00|0.52|1.05|0.79|0.00|0.43|0.37|0.87|1.14|1.79|0.73|0.00$0.47|0.52|2.16|1.15|0.41|0.95|0.64|3.03|0.89|0.62|0.53|0.98|0.68|0.61|0.63|1.03|0.39|0.63|0.83|0.76$27.8|94.7|60.1|60.6|15.5|68.7|68.2|24.5|50.7|22.8|27.6|103.0|33.5|25.5|51.5|42.0|45.0|34.7|55.2|23.7$51.|5.|22.|19.|74.|16.|16.|52.|34.|66.|60.|3.|52.|58.|25.|35.|30.|49.|24.|64.$15.|67.|49.|50.|5.|56.|55.|10.|34.|13.|16.|85.|20.|10.|45.|32.|32.|17.|41.|14.$1.7|0.1|0.4|0.4|4.6|0.3|0.3|1.8|0.8|3.1|2.4|0.05|1.9|2.2|0.6|0.8|0.7|1.6|0.5|2.9$0.3|-1.4|-0.5|-0.6|0.9|-0.7|-0.7|0.3|-0.1|0.7|0.5|-1.8|0.4|0.5|-0.3|-0.1|-0.2|0.3|-0.4|0.6$0.87|0.85|0.09|0.66|1.52|0.00|0.67|0.10|0.87|3.15|2.17|1.64|1.67|2.87|2.77|0.07|0.07|3.77|2.67|1.87$2.34|1.18|2.02|2.01|1.65|2.17|2.19|2.34|1.82|2.36|2.36|2.18|2.28|1.83|1.99|2.21|2.10|2.38|2.20|2.32$0.077|0.051|0.043|0.052|0.020|0.041|0.062|0.074|0.023|0.053|0.091|0.059|0.024|0.040|0.051|0.069|0.059|0.014|0.032|0.066$100.|83.|104.|86.|44.|84.|77.|50.|91.|103.|54.|72.|93.|51.|58.|117.|107.|25.|50.|98.$5.3|2.6|3.0|3.6|1.3|2.4|3.3|4.8|1.4|3.1|4.7|4.1|1.1|2.3|2.5|4.5|3.7|0.8|2.3|4.2$685.|382.|397.|400.|241.|313.|427.|707.|155.|394.|581.|575.|132.|303.|366.|593.|490.|99.|292.|553.$1.36|1.00|0.89|1.04|0.82|1.14|1.48|0.63|1.11|1.08|1.21|1.22|1.45|1.05|0.52|0.74|0.81|0.97|0.79|0.94$0.81|0.85|0.62|0.71|1.17|0.98|0.53|0.88|0.92|1.48|1.24|0.77|1.05|1.20|0.61|0.92|1.18|1.18|1.23|1.66$1.45|1.15|0.64|0.91|0.70|1.14|1.29|0.53|1.13|1.23|1.56|1.27|1.83|1.20|0.21|0.48|0.77|1.17|0.74|1.10$0.75|0.79|0.33|0.31|1.46|0.75|0.46|0.83|0.83|1.87|1.56|0.66|0.86|1.37|0.52|0.82|1.36|0.79|1.08|2.00$1.041|1.038|1.117|1.033|0.960|1.165|1.094|1.142|0.982|1.002|0.967|1.093|0.947|0.930|1.055|1.169|1.073|0.925|0.961|0.982$0.946|1.028|1.006|1.089|0.878|1.025|1.036|1.042|0.952|0.892|0.961|1.082|0.862|0.912|1.085|1.048|1.051|0.917|0.930|0.927$0.892|0.901|0.930|0.932|0.925|0.885|0.933|0.923|0.894|0.872|0.921|1.057|0.804|0.914|0.932|0.923|0.934|0.803|0.837|0.913$49.1|133.|-3.6|0.|0.|20.|0.|64.6|75.7|18.9|15.6|0.|6.8|54.7|43.8|44.4|31.0|70.5|0.|29.5$0.|1.|0.|-1.|0.|0.|-1.|0.|0.|0.|0.|1.|0.|0.|0.|0.|0.|0.|0.|0.$4.60|6.50|5.90|5.70|-1.00|6.10|5.60|7.60|4.50|2.60|3.25|7.90|1.40|3.20|7.00|5.25|4.80|4.00|4.35|3.40$4.32|6.55|6.24|6.04|1.73|6.13|6.17|6.09|5.66|2.31|3.93|7.92|2.44|2.59|7.19|5.37|5.16|2.78|3.58|3.31$0.28|0.34|0.31|0.33|0.11|0.39|0.37|0.28|0.23|0.12|0.16|0.59|0.08|0.10|0.46|0.27|0.26|0.15|0.25|0.22$27.5|105.0|58.7|40.0|44.6|80.7|62.0|0.0|79.0|93.5|93.5|100.0|94.1|115.5|41.9|29.3|51.3|145.5|117.3|71.5$1.8|-4.5|-3.5|-3.5|2.5|-3.5|-3.5|-0.4|-3.2|4.5|3.8|-3.9|1.9|2.8|-1.6|-0.8|-0.7|-0.9|-1.3|4.2$-0.48|-0.06|-0.87|-0.75|-0.32|-0.32|-0.71|0.00|-0.51|0.81|1.02|-0.09|0.81|1.03|2.03|0.05|-0.35|0.66|1.24|0.56$-0.5|3.0|0.2|2.5|-1.0|0.2|2.5|0.0|-0.5|-1.8|-1.8|3.0|-1.3|-2.5|-1.4|0.3|-0.4|-3.4|-2.3|-1.5$0.77|3.72|1.98|1.99|1.38|2.58|2.63|0.00|2.76|1.83|2.08|2.94|2.34|2.97|1.42|1.28|1.43|3.58|3.36|1.49$121.9|121.4|117.5|121.2|113.7|118.0|118.2|0.|118.2|118.9|118.1|122.0|113.1|118.2|81.9|117.9|117.1|118.4|110.0|121.7$243.2|206.6|207.1|215.0|209.4|205.4|213.6|300.0|219.9|217.9|205.6|210.9|204.0|203.7|237.4|232.0|226.7|203.7|195.6|220.3$0.77|2.38|1.45|1.43|1.22|1.75|1.77|0.58|1.78|1.56|1.54|2.08|1.80|1.90|1.25|1.08|1.24|2.21|2.13|1.29$5.2|6.0|5.0|5.0|6.1|6.0|6.0|4.2|6.0|7.0|7.0|6.0|6.8|7.1|6.2|4.9|5.0|7.6|7.1|6.4$0.025|0.20|0.10|0.10|0.10|0.10|0.10|0.025|0.10|0.19|0.19|0.20|0.19|0.39|0.17|0.025|0.10|0.56|0.39|0.15$1.29|0.96|0.90|1.04|1.11|1.27|1.44|0.56|1.22|0.97|1.30|1.23|1.47|1.07|0.52|0.82|0.82|0.99|0.72|0.91$0.90|0.99|0.76|0.72|0.74|0.80|0.75|0.92|1.08|1.45|1.02|0.77|0.97|1.32|0.64|0.95|1.21|1.14|1.25|1.49$0.77|0.88|1.28|1.41|0.81|0.98|0.99|1.64|0.68|0.51|0.58|0.96|0.41|0.59|1.91|1.32|1.04|0.76|1.05|0.47$1.32|0.98|0.95|1.03|0.92|1.10|1.44|0.61|1.31|0.93|1.31|1.25|1.39|1.02|0.58|0.76|0.79|0.97|0.73|0.93$0.86|0.97|0.73|0.69|1.04|1.00|0.66|0.89|0.85|1.47|1.04|0.77|0.93|1.21|0.68|1.02|1.27|1.26|1.31|1.43$0.79|0.90|1.25|1.47|0.79|0.92|1.02|1.67|0.81|0.50|0.57|0.99|0.51|0.77|1.78|1.30|0.97|0.79|0.93|0.46$0.22|0.28|0.42|0.73|0.20|0.26|0.08|0.58|0.14|0.22|0.19|0.27|0.38|0.08|0.46|0.55|0.49|0.43|0.46|0.08$0.92|0.93|0.60|0.48|1.16|0.95|0.61|0.61|0.93|1.81|1.30|0.70|1.19|1.25|0.40|0.82|1.12|1.54|1.53|1.81$1.00|0.68|0.54|0.50|0.91|0.28|0.59|0.79|0.38|2.60|1.42|0.59|1.49|1.30|0.35|0.70|0.59|0.89|1.08|2.63$0.90|1.02|0.62|0.47|1.24|1.18|0.62|0.56|1.12|1.54|1.26|0.74|1.09|1.23|0.42|0.87|1.30|1.75|1.68|1.53$12.97|11.72|11.42|10.85|14.63|11.76|11.89|12.43|12.16|15.67|14.90|11.36|14.39|14.00|11.37|11.23|11.69|13.93|13.42|15.71$1.43|1.18|0.64|0.92|0.94|1.22|1.67|0.46|0.98|1.04|1.36|1.27|1.53|1.19|0.49|0.70|0.78|1.01|0.69|0.98$0.86|0.94|0.74|0.72|1.17|0.89|0.62|0.97|1.06|1.24|0.98|0.79|1.08|1.16|1.22|1.04|1.18|1.07|1.25|1.33$0.64|0.62|3.14|1.92|0.32|0.80|1.01|0.63|2.05|0.92|0.37|0.89|1.07|0.86|0.50|1.01|0.92|1.00|1.31|0.87$0.17|0.76|2.62|1.08|0.95|0.91|0.28|5.02|0.57|0.26|0.21|1.17|0.00|0.28|0.12|0.57|0.23|0.00|0.97|0.24$1.13|0.48|1.11|1.18|0.38|0.41|1.02|3.84|0.30|0.40|0.65|1.13|0.00|0.45|0.00|0.81|0.71|0.93|0.38|0.48$1.00|1.18|0.87|1.39|1.09|1.13|1.04|0.46|0.71|0.68|1.01|1.05|0.36|0.65|1.95|1.56|1.23|1.10|0.87|0.58$4.34|26.66|13.28|12.00|35.77|17.56|17.26|0.00|21.81|19.06|18.78|21.29|21.64|29.40|10.93|6.35|11.01|42.53|31.53|13.92$0.5|0.8|0.8|-8.2|-6.8|-4.8|-16.9|0.0|-3.5|13.9|8.8|0.1|4.8|13.2|6.1|1.2|2.7|14.9|6.1|2.7$-0.1|-4.5|-1.6|-2.8|-2.2|-2.5|-7.5|-0.5|0.8|11.8|10.0|-3.2|7.1|13.9|8.0|-3.7|1.5|18.1|8.2|3.3$1.1|-0.4|-4.2|-1.6|7.1|-2.9|0.7|-0.2|-0.7|8.5|11.0|-1.9|5.4|13.4|4.4|-3.2|-1.7|17.1|7.4|5.9$1.0|-2.0|-3.0|-0.5|4.6|-2.0|1.1|0.2|-2.2|7.0|9.6|-3.0|4.0|12.6|3.1|-2.9|-0.6|15.1|6.7|4.6$0.93|0.98|0.98|1.01|0.88|1.02|1.02|1.01|0.89|0.79|0.85|1.05|0.84|0.78|1.00|1.02|0.99|0.83|0.93|0.81$0.94|1.09|1.04|1.08|0.84|1.11|1.12|1.01|0.92|0.76|0.82|1.23|0.83|0.73|1.04|1.04|1.02|0.87|1.03|0.81$87.|81.|70.|71.|104.|66.|72.|90.|90.|105.|104.|65.|100.|108.|78.|83.|83.|94.|83.|94.$2.36|1.92|1.70|1.67|3.36|1.75|1.74|2.06|2.41|4.17|3.93|1.23|4.22|4.37|1.89|1.81|2.04|3.82|2.91|3.49$1.29|0.83|0.77|1.00|0.94|1.10|1.54|0.72|1.29|0.94|1.23|1.23|1.23|1.23|0.70|0.78|0.87|1.06|0.63|0.97$0.96|0.67|0.72|0.90|1.13|1.18|0.33|0.90|0.87|1.54|1.26|0.81|1.29|1.37|0.75|0.77|1.23|1.13|1.07|1.41$0.72|1.33|1.38|1.04|1.01|0.81|0.75|1.35|0.76|0.80|0.63|0.84|0.62|0.58|1.43|1.34|1.03|0.87|1.35|0.83$7.99|5.86|4.33|5.14|1.81|3.98|6.10|6.91|2.17|5.48|9.16|6.01|2.50|3.83|4.95|6.84|5.77|1.34|3.15|6.65$3.73|3.34|2.33|2.23|2.30|2.36|3.|3.36|1.55|2.52|3.40|3.36|1.37|1.94|3.18|2.83|2.63|1.15|1.76|2.53$5.74|1.92|5.25|2.11|1.03|2.30|2.63|5.66|2.30|9.12|15.36|3.20|5.30|6.51|4.79|7.55|7.51|2.51|4.08|5.12$-0.60|-1.18|0.39|-1.36|-0.34|-0.71|-1.16|-0.37|0.08|1.44|1.82|-0.84|2.04|1.38|-0.05|0.25|0.66|1.02|0.53|-0.60$5.88|1.54|4.38|1.70|1.11|2.30|2.60|5.29|2.33|8.78|16.52|2.58|6.00|6.58|5.29|7.68|8.38|2.89|3.51|4.66$-0.57|-1.29|0.02|-1.54|-0.30|-0.71|-1.17|-0.48|0.10|1.31|2.16|-1.02|2.55|1.42|0.11|0.30|0.99|1.35|0.20|-0.79$5.39|2.81|7.31|3.07|0.86|2.31|2.70|6.52|2.23|9.94|12.64|4.67|3.68|6.34|3.62|7.24|5.44|1.64|5.42|6.18$-0.70|-0.91|1.28|-0.93|-0.41|-0.71|-1.13|-0.12|0.04|1.77|1.02|-0.40|0.86|1.29|-0.42|0.14|-0.13|0.26|1.29|-0.19$9.25|3.96|3.71|3.89|1.07|3.17|4.80|8.51|1.88|6.47|10.94|3.50|3.14|6.36|4.36|6.26|5.66|2.22|3.28|7.55$0.34|-0.57|-0.27|-0.56|-0.32|-0.34|-0.43|0.48|-0.19|0.39|0.52|-0.75|0.47|1.30|-0.19|-0.20|-0.04|0.77|0.07|0.36$10.17|1.21|1.36|1.18|1.48|1.57|1.15|8.87|1.07|10.91|16.22|1.04|4.12|9.60|2.24|5.38|5.61|2.67|2.68|11.44$6.61|0.41|1.84|0.59|0.83|1.20|1.63|4.88|1.14|12.91|21.66|1.15|7.17|7.76|3.51|6.84|8.89|2.11|2.57|6.30$1.61|0.40|0.73|0.75|0.37|0.61|1.50|3.12|0.46|1.61|1.37|0.62|1.59|1.24|0.67|0.68|0.92|1.63|0.67|1.30$8.63|6.75|4.18|6.24|1.03|4.76|7.82|6.80|2.70|3.48|8.44|6.25|2.14|2.73|6.28|8.53|4.43|0.80|2.54|5.44$10.88|6.01|5.75|6.13|0.69|4.68|9.34|7.72|2.15|1.80|8.03|6.11|3.79|2.93|7.21|7.25|3.51|0.47|1.01|4.57$5.15|4.38|4.81|5.75|3.24|4.45|7.05|6.38|2.69|4.40|8.11|5.25|1.60|3.52|5.65|8.04|7.41|1.68|3.42|7.00$5.04|3.73|5.94|5.26|2.20|4.50|6.07|7.09|2.99|4.32|9.88|6.31|1.85|3.72|6.22|8.05|5.20|2.10|3.32|6.19$9.90|0.09|0.94|0.35|2.55|0.87|0.08|8.14|0.20|15.25|22.28|0.16|1.85|6.47|2.38|4.17|4.33|2.21|3.42|14.34$6.69|6.65|4.49|4.97|1.70|5.39|7.76|6.32|2.11|4.51|8.23|8.36|2.46|3.59|5.20|7.40|5.18|1.06|2.75|5.27$5.08|4.75|5.75|5.96|2.95|4.24|6.04|8.20|2.10|4.95|8.03|4.93|2.61|4.36|4.84|6.41|5.87|2.31|4.55|6.07$9.36|0.27|2.31|0.94|2.56|1.14|0.94|6.17|0.47|13.73|16.64|0.58|3.93|10.99|1.96|5.58|4.68|2.20|3.13|12.43$0.23|-0.26|-0.94|-1.13|1.78|-0.57|-0.75|-0.07|0.11|1.19|1.03|-1.05|0.66|0.48|-0.76|-0.67|-0.36|0.90|0.59|1.24$-0.22|-0.93|-2.65|-4.12|4.66|-2.76|-3.64|-1.62|1.28|5.58|5.01|-4.18|3.51|5.27|-3.03|-2.84|-1.20|5.20|2.15|4.45$0.5|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.5|1.8|1.8|0.0|1.3|2.5|0.0|0.0|0.4|3.4|2.3|1.5$-1.895|-1.475|-1.560|-1.518|-2.035|-1.521|-1.535|-1.898|-1.755|-1.951|-1.966|-1.374|-1.963|-1.864|-1.699|-1.753|-1.767|-1.869|-1.686|-1.981$-1.404|-0.921|-1.178|-1.162|-1.365|-1.116|-1.163|-1.364|-1.215|-1.189|-1.315|-1.074|-1.303|-1.135|-1.236|-1.297|-1.252|-1.030|-1.030|-1.254$-0.491|-0.554|-0.382|-0.356|-0.670|-0.405|-0.371|-0.534|-0.540|-0.762|-0.650|-0.300|-0.659|-0.729|-0.463|-0.455|-0.515|-0.839|-0.656|-0.728$-9.475|-16.225|-12.480|-12.144|-12.210|-13.689|-13.815|-7.592|-17.550|-15.608|-15.728|-12.366|-15.704|-20.504|-11.893|-10.518|-12.369|-26.166|-20.232|-13.867$-7.020|-10.131|-9.424|-9.296|-8.190|-10.044|-10.467|-5.456|-12.150|-9.512|-10.520|-9.666|-10.424|-12.485|-8.652|-7.782|-8.764|-14.420|-12.360|-8.778$2.01|0.84|0.03|-2.05|1.98|1.02|0.93|0.12|-0.14|3.70|2.73|2.55|1.75|2.68|0.41|1.47|2.39|2.49|2.23|3.50$1.34|0.95|2.49|3.32|1.07|1.49|2.20|2.07|1.27|0.66|0.54|0.61|0.70|0.80|2.12|0.94|1.09|-4.65|-0.17|1.32$0.46|-1.54|1.31|-0.33|0.20|-1.12|0.48|0.64|-1.31|3.28|0.43|-1.71|0.15|0.52|-0.58|-0.83|-1.52|1.25|-2.21|0.54$-2.49|2.55|2.27|8.86|-3.13|1.79|4.04|-0.56|4.22|-10.87|-7.16|-9.97|-4.96|-6.64|5.19|-1.60|-4.75|-17.84|9.25|-3.97$4.55|5.97|5.56|2.85|-0.78|4.15|5.16|9.14|4.48|2.10|3.24|10.68|2.18|4.37|5.14|6.78|8.60|1.97|2.40|3.81$1.30|0.93|0.90|1.02|0.92|1.04|1.43|0.63|1.33|0.87|1.30|1.23|1.32|1.09|0.63|0.78|0.80|1.03|0.71|0.95$1.32|1.04|0.74|0.97|0.70|1.25|1.48|0.59|1.06|1.01|1.22|1.13|1.47|1.10|0.57|0.77|0.86|1.02|0.72|1.05$0.81|1.03|0.81|0.71|1.12|1.03|0.59|0.94|0.85|1.47|1.03|0.77|0.96|1.13|0.75|1.02|1.19|1.24|1.35|1.44$0.90|0.75|0.82|0.75|1.12|0.95|0.44|0.83|0.86|1.59|1.24|0.75|0.94|1.41|0.46|0.70|1.20|1.28|1.45|1.73$0.84|0.91|1.48|1.28|0.69|1.|0.78|1.76|0.53|0.55|0.49|0.95|0.52|0.88|1.47|1.29|1.05|0.88|1.28|0.51$0.65|0.93|1.45|1.47|1.43|0.94|0.75|1.53|0.96|0.57|0.56|0.95|0.71|0.72|1.51|1.46|0.96|0.90|1.12|0.55$1.08|0.93|1.05|0.86|1.22|0.95|1.09|0.85|1.02|0.98|1.04|1.01|1.11|0.96|0.91|0.95|1.15|1.17|0.80|1.03$1.34|0.91|0.83|1.06|1.27|1.13|1.69|0.47|1.11|0.84|1.39|1.08|0.90|1.02|0.48|1.05|0.74|0.64|0.73|1.18$1.15|1.06|0.87|1.|1.03|1.43|1.37|0.64|0.95|0.99|1.22|1.20|1.45|0.92|0.72|0.84|0.97|1.11|0.72|0.82$0.89|1.06|0.67|0.71|1.04|1.06|0.72|0.87|1.04|1.14|1.02|1.|1.41|1.32|0.69|0.86|1.15|1.06|1.35|1.66$0.82|0.99|1.27|0.98|0.71|1.01|0.54|0.94|1.26|1.67|0.94|0.73|1.30|1.56|0.69|0.65|0.98|1.25|1.26|1.22$0.98|1.03|0.66|0.74|1.01|0.63|0.59|0.90|1.17|1.38|1.05|0.83|0.82|1.23|0.73|0.98|1.20|1.26|1.23|1.62$0.69|0.|1.52|2.42|0.|1.44|0.63|2.64|0.22|0.43|0.|1.18|0.88|2.20|1.34|1.43|0.28|0.|1.53|0.14$0.87|1.30|1.36|1.24|0.83|1.06|0.91|1.69|0.91|0.27|0.67|0.66|0.|0.47|1.54|1.08|1.12|1.24|0.54|0.69$0.91|0.77|1.32|0.90|0.50|1.06|0.53|1.61|1.08|0.36|0.77|1.27|0.76|0.37|1.62|1.34|0.87|1.10|1.24|0.52$0.92|0.90|1.57|1.22|0.62|0.66|0.92|1.61|0.39|0.79|0.50|0.86|0.50|0.96|1.30|1.40|1.11|0.57|1.78|0.50$2.1|4.2|7.0|10.0|1.4|6.0|7.8|5.7|2.1|-8.0|-9.2|5.7|-4.2|-9.2|2.1|6.5|5.2|-10.0|-1.9|-3.7$-2.89|-3.30|-3.41|-3.38|-2.49|-3.15|-2.94|-3.25|-2.84|-1.72|-1.61|-3.31|-1.84|-1.63|-2.50|-3.30|-2.91|-1.75|-2.42|-2.08$12.28|11.49|11.00|10.97|14.93|11.28|11.19|12.01|12.84|14.77|14.10|10.80|14.33|13.43|11.19|11.26|11.65|12.95|13.29|15.07$7.62|6.81|6.17|6.18|10.93|6.67|6.38|7.31|7.85|9.99|9.37|5.72|9.83|8.99|6.64|6.93|7.08|8.41|8.53|10.38$2.63|2.45|2.27|2.29|3.36|2.45|2.31|2.55|2.57|3.08|2.98|2.12|3.18|3.02|2.46|2.60|2.55|2.85|2.79|3.21$13.65|11.28|12.24|10.98|14.49|11.30|12.55|15.36|11.59|14.63|14.01|11.96|13.40|14.08|11.51|11.26|13.00|12.06|12.64|12.88$14.60|13.24|11.79|13.78|15.90|12.02|13.59|14.18|15.35|14.10|16.49|13.28|16.23|14.18|14.10|13.36|14.50|13.90|14.76|16.30$10.67|11.05|10.85|10.21|14.15|11.71|11.71|10.95|12.07|12.95|13.07|9.93|15.00|13.27|10.62|11.18|10.53|11.41|11.52|13.86$3.70|2.53|2.12|2.60|3.03|2.70|3.30|3.13|3.57|7.69|5.88|1.79|5.21|6.60|2.12|2.43|2.60|6.25|3.03|7.14$6.05|5.70|5.04|4.95|7.86|5.45|5.10|6.16|5.80|7.51|7.37|4.88|6.39|6.62|5.65|5.53|5.81|6.98|6.73|7.62$0.305|0.227|0.322|0.335|0.339|0.306|0.282|0.352|0.215|0.278|0.262|0.391|0.280|0.195|0.346|0.326|0.251|0.291|0.293|0.291$0.175|0.083|0.090|0.140|0.074|0.093|0.135|0.201|0.125|0.100|0.104|0.058|0.054|0.104|0.136|0.155|0.152|0.092|0.081|0.096$0.687|0.590|0.489|0.632|0.263|0.527|0.669|0.670|0.594|0.564|0.541|0.407|0.328|0.577|0.600|0.692|0.713|0.632|0.495|0.529$-6.70|51.50|20.10|38.50|-8.40|17.20|34.30|-4.20|12.60|-13.|-11.70|36.80|-14.20|-15.50|0.80|-2.50|-5.|-7.90|2.90|-10.90$1.29|0.96|0.90|1.04|1.11|1.27|1.44|0.56|1.22|0.97|1.30|1.23|1.47|1.07|0.52|0.82|0.82|0.99|0.72|0.91$0.90|0.99|0.76|0.72|0.74|0.80|0.75|0.92|1.08|1.45|1.02|0.77|0.97|1.32|0.64|0.95|1.21|1.14|1.25|1.49$0.78|0.88|1.28|1.41|0.80|0.97|1.|1.64|0.69|0.51|0.59|0.96|0.39|0.58|1.91|1.33|1.03|0.75|1.05|0.47$1.10|0.95|0.80|0.65|0.95|1.00|1.00|0.60|0.85|1.10|1.25|1.00|1.15|1.10|0.10|0.75|0.75|1.10|1.10|0.95$1.00|0.70|0.60|0.50|1.90|1.00|0.70|0.30|0.80|4.00|2.00|0.70|1.90|3.10|0.20|0.90|1.70|2.20|2.80|4.00$0.12|0.04|-0.10|0.01|-0.25|-0.03|-0.02|-0.02|-0.06|-0.07|0.05|0.26|0.00|0.05|-0.19|-0.19|-0.04|-0.06|-0.14|-0.03$0.26|-0.14|-0.03|0.15|-0.15|-0.13|0.21|-0.37|0.10|-0.03|-0.02|0.12|0.00|0.12|-0.08|0.01|-0.34|-0.01|-0.29|0.02$0.64|-0.10|0.09|0.33|0.03|-0.23|0.51|-0.09|-0.23|-0.22|0.41|-0.17|0.13|-0.03|-0.43|-0.10|-0.07|-0.02|-0.38|-0.01$0.29|-0.03|-0.04|0.11|-0.05|0.26|0.28|-0.67|-0.26|0.00|0.47|-0.19|0.27|0.24|-0.34|-0.17|-0.20|0.25|-0.30|-0.01$0.68|-0.22|-0.09|-0.02|-0.15|-0.15|0.44|-0.73|-0.14|-0.08|0.61|0.03|0.39|0.06|-0.76|-0.26|-0.10|0.20|-0.04|0.12$0.34|0.22|-0.33|0.06|-0.18|0.01|0.20|-0.88|-0.09|-0.03|0.20|-0.11|0.43|0.15|-0.81|-0.35|-0.37|0.07|-0.31|0.13$0.57|0.23|-0.36|-0.46|-0.15|0.15|0.26|-0.71|-0.05|0.00|0.48|0.16|0.41|0.03|-1.12|-0.47|-0.54|-0.10|-0.35|0.31$0.33|0.10|-0.19|-0.44|-0.03|0.19|0.21|-0.46|0.27|-0.33|0.57|0.23|0.79|0.48|-1.86|-0.23|-0.33|0.15|-0.19|0.24$0.13|0.08|-0.07|-0.71|-0.09|0.12|0.13|-0.39|0.32|0.00|0.50|0.37|0.63|0.15|-1.40|-0.28|-0.21|0.02|-0.10|0.17$0.31|0.18|-0.10|-0.81|-0.26|0.41|-0.06|-0.42|0.51|-0.15|0.56|0.47|0.58|0.10|-1.33|-0.49|-0.44|0.14|-0.08|-0.01$0.21|0.07|-0.04|-0.58|-0.12|0.13|-0.23|-0.15|0.37|0.31|0.70|0.28|0.61|-0.06|-1.03|-0.28|-0.25|0.21|0.16|0.00$0.18|0.21|-0.03|-0.32|-0.29|-0.27|-0.25|-0.40|0.28|-0.03|0.62|0.41|0.21|0.05|-0.84|-0.05|-0.16|0.32|0.11|0.06$-0.08|0.05|-0.08|-0.24|-0.25|-0.28|-0.19|-0.10|0.29|-0.01|0.28|0.45|0.11|0.00|-0.42|0.07|-0.33|0.36|0.00|-0.13$-0.18|-0.13|0.28|0.05|-0.26|0.21|-0.06|0.23|0.24|-0.42|-0.23|0.03|-0.42|-0.18|-0.13|0.41|0.33|-0.10|-0.10|-0.07$-0.01|0.02|0.41|-0.09|-0.27|0.01|0.09|0.13|0.22|-0.27|-0.25|0.08|-0.57|-0.12|0.26|0.44|0.35|-0.15|0.15|-0.09$-0.19|0.03|0.02|-0.06|-0.29|0.02|-0.10|0.19|-0.16|-0.08|-0.42|-0.09|-0.38|-0.32|0.05|0.25|0.22|-0.19|0.05|-0.15$-0.14|0.14|-0.27|-0.10|-0.64|-0.11|-0.39|0.46|-0.04|0.16|-0.57|0.04|0.24|0.08|0.02|-0.12|0.00|-0.10|0.18|0.29$-0.31|0.25|-0.53|-0.54|-0.06|0.07|-0.52|0.37|-0.32|0.57|0.09|-0.29|0.29|0.24|-0.31|0.11|0.03|0.15|0.29|0.48$-0.10|0.19|-0.89|-0.89|0.13|-0.04|-0.34|-0.45|-0.34|0.95|0.32|-0.46|0.43|0.36|-0.91|-0.12|0.49|0.34|0.42|0.76$-0.25|-0.02|-0.77|-1.01|0.13|-0.12|-0.62|-0.72|-0.16|1.10|0.23|-0.59|0.32|0.48|-1.24|-0.31|0.17|0.45|0.77|0.69$-0.26|-0.09|-0.34|-0.55|0.47|-0.33|-0.75|-0.56|-0.04|0.94|0.25|-0.55|-0.05|0.20|-1.28|-0.28|0.08|0.22|0.53|0.67$0.05|-0.11|-0.40|-0.11|0.36|-0.67|-0.35|0.14|0.02|0.47|0.32|-0.51|-0.10|0.20|-0.79|0.03|-0.15|0.09|0.34|0.58$-0.44|-0.13|0.05|-0.20|0.13|-0.58|-0.28|0.08|0.09|-0.04|-0.12|-0.33|-0.21|-0.13|-0.48|0.27|0.47|-0.22|-0.11|0.06$-0.31|-0.10|0.06|0.13|-0.11|-0.47|-0.05|0.45|-0.06|-0.25|-0.44|-0.44|-0.28|-0.04|-0.29|0.34|0.27|-0.08|0.06|0.11$-0.02|0.04|0.03|0.11|-0.02|-0.17|0.10|0.38|-0.09|-0.48|-0.26|-0.39|-0.14|-0.03|-0.04|0.41|0.36|-0.01|-0.08|-0.18$-0.06|0.02|0.10|0.24|-0.19|-0.04|-0.04|0.17|0.19|-0.20|-0.46|-0.43|-0.52|-0.33|0.37|0.43|0.50|-0.32|0.35|0.00$-0.05|0.06|0.00|0.15|0.30|-0.08|-0.02|-0.14|-0.07|0.26|0.04|-0.42|0.25|0.09|0.31|-0.11|-0.06|0.19|0.33|0.04$-0.19|0.17|-0.38|0.09|0.41|0.04|-0.20|0.28|-0.19|-0.06|0.34|-0.20|0.45|0.07|0.04|-0.23|-0.02|0.16|0.22|0.05$-0.43|0.06|0.00|-0.31|0.19|0.14|-0.41|-0.21|0.21|0.29|-0.10|0.33|-0.01|0.25|0.28|-0.23|-0.26|0.15|0.09|-0.10$-0.19|-0.07|0.17|-0.27|0.42|-0.29|-0.22|0.17|0.17|-0.34|-0.22|0.00|-0.53|-0.31|0.14|0.22|0.10|-0.15|-0.02|-0.33$-0.25|0.12|0.61|0.60|0.18|0.09|-0.12|0.09|0.42|-0.54|-0.55|0.14|-0.47|-0.29|0.89|0.24|0.16|-0.44|-0.19|-0.45$-0.27|-0.40|0.71|0.54|0.00|-0.08|-0.12|1.14|0.18|-0.74|-0.54|0.45|-0.76|-0.47|1.40|0.40|-0.10|-0.46|-0.05|-0.86$-0.42|-0.23|0.81|0.95|-0.18|-0.01|-0.09|1.24|0.05|-1.17|-0.69|0.09|-0.86|-0.39|1.77|0.63|0.29|-0.37|-0.41|-1.32$-0.24|-0.04|0.45|0.65|-0.38|0.01|0.07|0.85|-0.21|-0.65|-0.80|0.17|-0.71|-0.61|2.27|0.33|0.13|-0.44|-0.49|-0.99$-0.14|0.21|0.35|0.66|-0.09|0.11|0.06|0.36|-0.31|-0.51|-0.80|-0.14|-0.56|-0.25|1.59|0.32|0.21|-0.17|-0.35|-0.70$0.01|-0.13|-0.11|0.78|-0.31|-0.13|0.09|0.14|-0.56|-0.09|-0.81|-0.43|-0.49|-0.20|1.14|0.13|-0.02|-0.20|0.10|-0.11$-0.30|-0.09|-0.12|0.44|0.03|0.24|0.18|-0.12|-0.20|-0.07|-0.18|0.06|-0.44|0.11|0.77|-0.09|-0.27|-0.09|-0.25|-0.06$-0.23|-0.20|0.06|0.34|0.19|0.47|0.28|0.14|-0.22|0.42|-0.36|-0.15|-0.19|-0.02|0.78|-0.29|-0.30|-0.18|0.07|0.29$0.08|-0.01|-0.06|0.04|0.37|0.48|0.36|-0.02|-0.45|0.09|0.24|-0.27|0.16|0.34|0.16|-0.35|-0.04|-0.06|-0.20|0.18$0.934|0.962|0.986|0.994|0.900|1.047|0.986|1.015|0.882|0.766|0.825|1.040|0.804|0.773|1.047|1.056|1.008|0.848|0.931|0.825$0.941|1.112|1.038|1.071|0.866|1.150|1.100|1.055|0.911|0.742|0.798|1.232|0.781|0.723|1.093|1.082|1.043|0.867|1.050|0.817$1.16|1.72|1.97|2.66|0.50|3.87|2.40|1.63|0.86|0.57|0.51|3.90|0.40|0.43|2.04|1.61|1.48|0.75|1.72|0.59$0.85|2.02|0.88|1.50|0.90|1.71|1.79|1.54|1.59|0.67|1.03|0.88|1.17|0.85|1.47|1.50|1.96|0.83|1.34|0.89$1.58|1.14|0.77|0.98|1.04|1.24|1.49|0.66|0.99|1.09|1.21|1.27|1.41|1.00|1.46|1.05|0.87|1.23|0.68|0.88$0.82|2.60|2.07|2.64|0.00|0.00|2.62|1.63|0.00|2.32|0.00|2.86|0.00|0.00|0.00|1.23|2.48|0.00|1.90|1.62$0.78|1.75|1.32|1.25|3.14|0.93|0.94|1.13|1.03|1.26|0.91|0.85|0.41|1.07|1.73|1.31|1.57|0.98|1.31|1.11$0.88|0.99|1.02|1.16|1.14|0.93|1.01|0.70|1.87|1.61|1.09|0.83|1.71|1.52|0.87|1.14|0.96|1.96|1.68|1.56$0.30|0.90|2.73|1.26|0.72|0.97|1.33|3.09|1.33|0.45|0.96|0.71|1.89|1.20|0.83|1.16|0.97|1.58|0.86|0.64$0.40|1.20|1.24|1.59|2.98|0.50|1.26|1.89|2.71|1.31|0.57|0.87|0.00|1.27|0.38|0.92|1.38|1.53|1.79|0.95$1.48|1.02|0.99|1.19|0.86|1.42|1.43|0.46|1.27|1.12|1.33|1.36|1.41|1.30|0.25|0.89|0.81|1.27|0.91|0.93$0.00|0.00|4.14|2.15|0.00|0.00|0.00|6.49|0.00|0.00|0.00|0.00|0.00|2.11|1.99|0.00|1.24|0.00|1.90|0.00$1.02|1.00|1.31|1.76|1.05|1.05|0.83|2.39|0.40|0.83|1.06|0.94|1.33|0.41|2.73|1.18|0.77|1.22|1.09|0.88$0.93|1.52|0.92|0.60|1.08|0.94|0.73|0.78|1.08|1.74|1.03|1.00|1.31|1.51|1.37|0.97|1.38|1.12|1.65|1.70$0.99|1.19|1.15|1.18|2.32|1.52|1.36|1.40|1.06|0.81|1.26|0.91|1.00|1.25|0.00|1.50|1.18|1.33|1.09|1.01$17.05|21.25|34.81|19.27|28.84|15.42|20.12|38.14|23.07|16.66|10.89|16.46|20.61|16.26|23.94|19.95|18.92|23.36|26.49|17.06$14.53|17.82|13.59|19.78|30.57|22.18|18.19|37.16|22.63|20.28|14.30|14.07|20.61|19.61|52.63|18.56|21.09|19.78|26.36|21.87$1.81|-14.92|-6.64|-8.72|1.28|-5.54|-6.81|0.94|-4.66|4.92|4.92|-5.55|2.35|2.98|0.|-3.40|-2.57|2.33|-0.14|4.04$0.52|-1.32|-0.01|0.|0.|-0.07|-0.79|0.|0.95|2.04|1.76|0.08|1.32|2.09|0.|0.04|0.27|2.51|1.63|1.18$0.13|-5.|-3.04|-2.23|-2.52|-3.84|-3.43|1.45|-5.61|-2.77|-2.64|-3.97|-3.83|-3.74|0.|-1.66|-2.31|-8.21|-5.97|-2.05$1.29|-13.60|-6.63|0.|0.|-5.47|-6.02|0.94|-5.61|2.88|3.16|-5.63|1.03|0.89|0.|-3.44|-2.84|-0.18|-1.77|2.86$1.42|-18.60|-9.67|0.|0.|-9.31|-9.45|2.39|-11.22|0.11|0.52|-9.60|-2.80|-2.85|0.|-5.10|-5.15|-8.39|-7.74|0.81$93.7|250.4|146.3|142.6|135.2|177.7|182.9|52.6|188.1|182.2|173.7|215.2|197.6|228.6|0.|109.5|142.1|271.6|239.9|157.2$-0.29|-2.71|-1.18|-1.02|0.|-1.53|-0.90|-0.34|-0.94|0.24|-0.12|-2.05|-0.24|0.|0.|-0.75|-0.71|-0.59|-1.02|0.09$-0.06|-0.84|-0.48|-0.80|1.36|-0.73|-0.77|-0.41|0.49|1.31|1.21|-1.18|1.27|1.27|0.|-0.50|-0.27|0.88|0.33|1.09$0.7|0.4|1.2|1.4|0.6|1.|1.|1.6|1.2|0.9|0.9|1.|0.3|1.2|0.7|1.6|0.3|1.1|1.9|0.7$0.7|0.4|1.2|1.4|0.6|1.|1.|1.6|1.2|0.9|0.9|1.|0.3|1.2|0.7|1.6|0.3|1.1|1.9|0.7$0.5|0.4|3.5|2.1|0.6|0.4|0.4|1.8|1.1|0.2|0.2|0.7|0.8|0.2|0.8|2.3|1.6|0.3|0.8|0.1$1.2|0.7|0.7|0.8|0.8|0.7|2.2|0.3|0.7|0.9|0.9|0.6|0.3|0.5|2.6|0.7|0.8|2.1|1.8|1.1$1.6|0.9|0.7|2.6|1.2|0.8|2.|0.9|0.7|0.7|0.3|1.|1.|0.9|0.5|0.8|0.7|1.7|0.4|0.6$1.|0.4|0.7|2.2|0.6|1.5|3.3|0.6|0.7|0.4|0.6|0.8|1.|0.6|0.4|0.4|1.|1.4|1.2|1.1$1.1|1.5|0.|0.3|1.1|1.3|0.5|0.4|1.5|1.1|2.6|0.8|1.7|1.9|0.1|0.4|0.5|3.1|0.6|1.5$1.4|1.2|1.2|0.6|1.6|1.4|0.9|0.6|0.9|0.9|1.1|1.9|1.7|1.|0.3|1.1|0.6|1.4|0.2|0.8$1.8|1.3|0.9|1.|0.7|1.3|0.8|0.5|1.|1.2|1.2|1.1|1.5|1.3|0.3|0.6|1.|1.5|0.8|1.2$1.8|1.|0.6|0.7|0.|1.|1.1|0.5|2.4|1.3|1.2|1.4|2.7|1.9|0.3|0.5|0.5|1.1|1.3|0.4$1.3|0.8|0.6|0.5|0.7|0.2|0.7|0.5|1.9|1.6|1.4|1.|2.8|2.9|0.|0.5|0.6|2.1|0.8|1.4$0.7|0.8|0.8|0.6|0.2|1.3|1.6|0.1|1.1|1.4|1.9|2.2|1.|1.8|0.|0.6|0.7|0.4|1.1|1.3$1.4|2.1|0.9|0.7|1.2|1.6|1.7|0.2|1.8|0.4|0.8|1.9|1.3|0.3|0.2|1.6|0.9|0.4|0.3|0.7$1.1|1.|1.2|0.4|1.6|2.1|0.8|0.2|3.4|0.7|0.7|2.|1.|0.7|0.|1.7|1.|0.|1.2|0.7$0.8|0.9|1.6|0.7|0.4|0.9|0.3|3.9|1.3|0.7|0.7|1.3|0.8|0.5|0.7|0.8|0.3|0.|0.8|0.2$1.|1.4|0.9|1.4|0.8|1.4|0.8|1.2|1.2|1.1|0.9|1.2|0.8|0.1|1.9|0.7|0.8|0.4|0.9|0.6$0.7|1.1|1.5|1.4|0.4|1.1|0.7|0.6|1.|0.7|0.5|1.3|0.|1.2|1.5|0.9|2.1|2.7|0.5|1.$6.5|-0.9|-5.1|0.5|-1.3|1.0|7.8|-8.6|1.2|0.6|3.2|2.3|5.3|1.6|-7.7|-3.9|-2.6|1.2|-4.5|1.4$2.3|-5.2|0.3|7.4|0.8|-0.7|10.3|-5.2|-2.8|-4.0|-2.1|-4.1|-3.5|-1.1|8.1|-3.5|2.3|-0.9|-3.7|-4.4$6.7|0.3|-6.1|-3.1|-4.9|0.6|2.2|-6.8|-1.0|3.2|5.5|0.5|7.2|2.8|-22.8|-3.0|-4.0|4.0|-4.6|2.5$2.3|1.4|-3.3|-4.4|6.1|2.7|2.5|-8.3|5.9|-0.5|0.1|7.3|3.5|1.6|-24.4|-1.9|-3.7|-0.9|-0.6|2.3$-2.3|0.4|-4.1|-4.4|4.4|1.2|-5.0|-4.2|-2.5|6.7|2.3|-3.3|2.3|2.6|-1.8|-1.7|1.3|-1.0|4.0|6.8$-2.7|0.4|-4.2|-4.4|3.7|0.8|-8.1|-3.9|-3.0|7.7|3.7|-2.9|3.7|3.0|-6.6|-2.4|1.7|0.3|3.3|7.1$0.0|1.1|-2.0|-2.6|5.4|2.4|3.1|-3.4|0.8|-0.1|-3.7|-3.1|-2.1|0.7|7.4|1.3|0.0|-3.4|4.8|2.7$-5.0|2.1|4.2|3.1|4.4|0.4|-4.7|5.7|-0.3|-4.6|-5.6|1.0|-4.8|-1.8|2.6|2.6|0.3|3.4|2.9|-6.0$-3.3|0.0|5.4|3.9|-0.3|-0.4|-1.8|-1.2|3.0|-0.5|-2.3|-1.2|-4.3|0.8|6.5|1.8|-0.7|-0.8|3.1|-3.5$-4.7|2.0|3.9|1.9|6.2|-2.0|-4.2|5.7|-2.6|-7.0|-6.2|2.8|-4.8|-3.7|3.6|2.1|0.6|3.3|3.8|-6.2$-3.7|1.0|-0.6|-0.6|4.0|3.4|-4.3|5.9|-0.8|-0.5|-2.8|1.3|-1.6|1.6|-6.0|1.5|1.2|6.5|1.3|-4.6$-2.5|-1.2|4.6|0.0|-4.7|-0.5|-4.4|4.9|1.6|-3.3|-2.0|-0.8|-4.1|-4.1|5.8|2.5|1.7|1.2|-0.6|-3.5$-5.1|2.6|4.7|3.1|3.8|0.2|-5.2|5.6|-0.9|-4.5|-5.4|1.0|-5.3|-2.4|3.5|3.2|0.0|2.9|3.2|-6.3$-1.0|0.3|-0.7|-1.2|2.1|-0.1|-0.7|0.3|1.1|4.0|2.0|-0.9|1.8|2.8|0.4|-1.2|-0.5|3.0|2.1|1.4$86.6|162.2|103.3|97.8|132.3|119.2|113.9|62.9|155.8|158.0|164.1|115.5|172.9|194.1|92.9|85.6|106.5|224.6|177.7|141.0$0.74|0.64|0.63|0.62|0.91|0.62|0.62|0.72|0.78|0.88|0.85|0.52|0.85|0.88|0.64|0.66|0.70|0.85|0.76|0.86$-0.67|12.1|7.23|8.72|-0.34|6.39|7.35|0.00|3.82|-3.02|-3.02|6.13|-1.30|-3.24|-1.75|4.35|3.86|-2.86|0.98|-2.18$-0.67|3.89|2.27|1.57|-2.00|2.12|1.78|0.00|1.09|-3.02|-3.02|2.46|-1.67|-3.24|-1.75|0.10|-0.42|-2.86|0.98|-2.18$0.4|0.3|0.9|0.8|0.5|0.7|1.3|0.0|1.0|0.4|0.6|0.4|0.3|0.7|0.9|0.4|0.4|0.6|1.2|0.4$0.73|0.73|-0.01|0.54|0.70|-0.10|0.55|0.00|1.10|2.97|2.49|1.50|1.30|2.65|2.60|0.04|0.44|3.00|2.97|1.69$0.239|0.211|0.249|0.171|0.220|0.260|0.187|0.160|0.205|0.273|0.281|0.228|0.253|0.234|0.165|0.236|0.213|0.183|0.193|0.255$0.330|-0.176|-0.233|-0.371|0.074|-0.254|-0.409|0.370|-0.078|0.149|0.129|-0.075|-0.092|-0.011|0.370|0.022|0.136|-0.011|-0.138|0.245$-0.110|0.079|-0.136|-0.285|-0.184|-0.067|-0.246|-0.073|0.320|0.001|-0.008|0.049|-0.041|0.438|-0.016|-0.153|-0.208|0.493|0.381|-0.155$-0.062|-0.167|0.166|-0.079|0.380|-0.025|-0.184|-0.017|0.056|-0.309|-0.264|-0.371|0.077|0.074|-0.036|0.470|0.348|0.050|0.220|-0.212$1.071|1.033|0.784|0.680|0.922|0.977|0.970|0.591|0.850|1.140|1.140|0.939|1.200|1.086|0.659|0.760|0.817|1.107|1.020|0.950$8.0|0.1|0.1|70.0|26.0|33.0|6.0|0.1|0.1|55.0|33.0|1.0|54.0|18.0|42.0|0.1|0.1|77.0|66.0|0.1$-0.40|-0.59|-0.92|-1.31|0.17|-0.91|-1.22|-0.67|-0.64|1.25|1.22|-0.67|1.02|1.92|-0.49|-0.55|-0.28|0.50|1.67|0.91$1.42|1.06|0.71|1.01|0.73|1.02|1.63|0.50|1.20|1.12|1.29|1.24|1.21|1.16|0.65|0.71|0.78|1.05|0.67|0.99$0.946|1.128|0.432|1.311|0.481|1.615|0.698|0.360|2.168|1.283|1.192|1.203|0.000|0.963|2.093|0.523|1.961|1.925|0.802|0.409$0.790|1.087|0.832|0.530|1.268|1.038|0.643|0.725|0.864|1.361|1.111|0.735|1.092|1.052|1.249|1.093|1.214|1.114|1.340|1.428$1.194|0.795|0.659|1.056|0.678|1.290|0.928|1.015|0.611|0.603|0.595|1.060|0.831|0.377|3.159|1.444|1.172|0.452|0.816|0.640$0.497|0.677|2.072|1.498|1.348|0.711|0.651|1.848|1.474|0.471|0.656|0.932|0.425|1.348|0.179|1.151|0.749|1.283|1.283|0.654$0.937|1.725|1.080|1.640|1.004|1.078|0.679|0.901|1.085|0.178|0.808|1.254|0.886|0.803|0.748|1.145|1.487|0.803|1.227|0.625$0.289|1.380|3.169|0.917|1.767|2.372|0.285|4.259|1.061|0.262|0.000|1.288|0.000|0.393|0.000|0.160|0.218|0.000|0.654|0.167$0.328|2.088|1.498|3.379|0.000|0.000|0.000|0.500|1.204|2.078|0.414|0.835|0.982|1.336|0.415|1.089|1.732|1.781|0.000|0.946$0.945|0.364|1.202|1.315|0.932|0.704|1.014|2.355|0.525|0.673|0.758|0.947|1.028|0.622|0.579|1.140|0.863|0.777|0.907|0.561$0.842|0.936|1.352|1.366|1.032|0.998|0.758|1.349|1.079|0.459|0.665|1.045|0.668|0.881|1.385|1.257|1.055|0.881|1.101|0.643$0.135|0.296|0.196|0.289|0.159|0.236|0.184|0.051|0.223|0.173|0.215|0.170|0.239|0.087|0.151|0.010|0.100|0.166|0.066|0.285$0.507|0.459|0.287|0.223|0.592|0.383|0.445|0.390|0.310|0.111|0.619|0.559|0.431|0.077|0.739|0.689|0.785|0.160|0.060|0.356$0.159|0.194|0.385|0.283|0.187|0.236|0.206|0.049|0.233|0.581|0.083|0.159|0.198|0.682|0.366|0.150|0.074|0.463|0.737|0.301$.03731|.09593|.00359|.12630|.08292|.07606|.00580|.00499|.02415|.00000|.00000|.03710|.08226|.09460|.01979|.08292|.09408|.05481|.05159|.00569$0.|0.|0.|0.|0.|0.|0.|0.|0.|1.|1.|0.|0.|1.|0.|0.|0.|1.|1.|1.$-12.04|39.23|4.25|23.22|3.95|2.16|16.81|-7.85|6.28|-18.32|-17.79|9.71|-8.86|-21.98|5.82|-1.54|-4.15|-16.19|-1.51|-16.22$10.04|6.18|5.63|5.76|8.89|5.41|5.37|7.99|7.49|8.72|8.79|4.40|9.15|7.98|7.79|7.08|7.00|8.07|6.90|8.88$0.89|0.88|0.89|0.87|0.85|0.82|0.84|0.92|0.83|0.76|0.73|0.97|0.74|0.52|0.82|0.96|0.92|0.20|0.49|0.85$0.52|0.49|0.42|0.37|0.83|0.35|0.38|0.41|0.70|0.79|0.77|0.31|0.76|0.87|0.35|0.49|0.38|0.86|0.64|0.72$0.16|-0.20|1.03|-0.24|-0.12|-0.55|-0.45|-0.16|-0.18|-0.19|-0.44|-0.12|-0.79|-0.25|-0.59|-0.01|0.05|-0.33|-0.42|-0.46$0.15|-0.37|0.69|-0.22|-0.19|-0.06|0.14|0.36|-0.25|0.02|0.06|-0.16|0.11|1.18|0.11|0.13|0.28|-0.12|0.19|-0.08$-0.07|-0.40|-0.57|-0.80|0.17|-0.26|-0.63|0.27|-0.49|0.06|-0.17|-0.45|0.03|0.40|-0.47|-0.11|0.09|-0.61|-0.61|-0.11$7.0|9.1|10.0|13.0|5.5|8.6|12.5|7.9|8.4|4.9|4.9|10.1|5.3|5.0|6.6|7.5|6.6|5.3|5.7|5.6$1.94|-19.92|-9.68|-10.95|-1.24|-9.38|-10.20|2.39|-10.27|2.15|2.28|-9.52|-1.48|-0.76|-3.68|-5.06|-4.88|-5.88|-6.11|1.99$0.07|2.88|3.22|3.64|0.71|2.18|3.08|2.23|2.41|-4.44|-4.19|2.84|-2.49|-4.92|-1.22|1.96|0.92|-4.75|-1.39|-2.69$-1.73|2.52|1.45|1.13|-0.97|0.53|0.39|-5.36|1.74|-1.68|-1.03|1.41|-0.27|1.30|0.88|-1.63|-2.09|3.65|2.32|-2.53$0.09|-3.44|0.84|2.36|4.13|-1.14|-0.07|0.30|1.11|-1.03|-0.98|-3.14|-0.41|0.45|2.23|0.57|-1.40|0.85|0.01|-1.29$8.5|0.|8.2|8.5|11.0|6.3|8.8|7.1|10.1|16.8|15.0|7.9|13.3|11.2|8.2|7.4|8.8|9.9|8.8|12.0$6.8|0.|6.2|7.0|8.3|8.5|4.9|6.4|9.2|10.0|12.2|7.5|8.4|8.3|6.9|8.0|7.0|5.7|6.8|9.4$18.08|0.|17.47|17.36|18.17|17.93|18.16|18.24|18.49|18.62|18.60|17.96|18.11|17.30|18.16|17.57|17.54|17.19|17.99|18.30$18.56|0.|18.24|17.94|17.84|18.51|17.97|18.57|18.64|19.21|19.01|18.36|18.49|17.95|18.77|18.06|17.71|16.87|18.23|18.98$-0.152|-0.089|-0.203|-0.355|0.|-0.181|-0.411|-0.190|0.|-0.086|-0.102|-0.062|-0.107|0.001|-0.181|-0.203|-0.170|0.275|0.|-0.125$0.83|0.83|0.09|0.64|1.48|0.00|0.65|0.10|1.10|3.07|2.52|1.60|1.40|2.75|2.70|0.14|0.54|0.31|2.97|1.79$11.50|14.28|12.82|11.68|13.46|14.45|13.57|3.40|13.69|21.40|21.40|15.71|16.25|19.80|17.43|9.47|15.77|21.67|18.03|21.57$0.00|52.00|3.38|49.70|1.48|3.53|49.90|0.00|51.60|0.13|0.13|49.50|1.43|0.35|1.58|1.67|1.66|2.10|1.61|0.13$6.00|10.76|5.41|2.77|5.05|5.65|3.22|5.97|7.59|6.02|5.98|9.74|5.74|5.48|6.30|5.68|5.66|5.89|5.66|5.96$9.9|4.6|5.4|2.8|2.8|9.0|3.2|5.6|8.2|17.1|17.6|3.5|14.9|18.8|14.8|6.9|9.5|17.1|15.0|14.3$0.94|1.15|0.79|1.19|0.60|0.94|1.41|1.18|1.15|1.07|0.95|1.03|0.88|1.06|1.18|0.69|0.87|0.91|1.04|0.90$0.98|1.14|1.05|1.05|0.41|0.90|1.04|1.25|1.01|0.88|0.80|1.06|1.12|1.12|1.31|1.02|0.80|0.90|1.12|0.87$1.05|0.81|0.91|1.39|0.60|0.87|1.11|1.26|1.43|0.95|0.96|0.97|0.99|0.95|1.05|0.96|1.03|1.06|0.94|0.62$0.75|0.90|1.24|1.72|0.66|1.08|1.10|1.14|0.96|0.80|1.01|0.66|1.02|0.88|1.33|1.20|1.13|0.68|0.80|0.58$0.67|0.76|1.28|1.58|0.37|1.05|0.94|0.98|0.83|0.78|0.79|0.84|0.98|0.96|1.12|1.25|1.41|0.94|0.82|0.67$1.10|1.05|0.72|1.14|0.26|1.31|2.30|0.55|0.83|1.06|0.84|1.08|0.90|0.90|1.67|0.81|0.77|1.26|0.99|0.76$1.39|0.95|0.67|1.64|0.52|1.60|2.07|0.65|1.36|0.64|0.91|0.80|1.10|1.00|0.94|0.69|0.92|1.10|0.73|0.70$1.43|1.33|0.55|0.90|0.52|1.43|1.70|0.56|0.66|1.18|1.52|0.82|1.68|1.10|0.15|0.61|0.75|1.68|0.65|1.14$1.55|1.39|0.60|0.61|0.59|1.43|1.34|0.37|0.89|1.47|1.36|1.27|2.13|1.39|0.03|0.44|0.65|1.10|0.93|1.18$1.80|1.73|0.73|0.90|0.55|0.97|1.73|0.32|0.46|1.09|1.47|1.24|1.64|0.96|0.15|0.67|0.70|0.68|0.91|0.81$1.52|1.49|0.58|1.04|0.26|1.41|1.76|0.30|0.83|1.25|1.26|1.10|1.14|1.14|0.44|0.66|0.73|0.68|1.04|1.03$1.49|1.41|0.67|0.94|0.37|1.52|1.55|0.29|0.96|1.04|1.40|1.17|1.84|0.86|0.20|0.68|0.79|1.52|1.06|0.94$1.73|1.24|0.70|0.68|0.63|0.88|1.16|0.32|0.76|1.15|1.80|1.22|2.21|1.35|0.07|0.65|0.46|1.57|1.10|0.94$1.33|1.39|0.64|0.60|0.44|1.37|1.43|0.20|1.02|1.58|1.63|1.71|1.76|1.22|0.07|0.42|0.57|1.00|1.02|1.08$1.87|1.66|0.70|0.91|0.33|1.24|1.88|0.33|0.89|0.90|1.65|1.63|1.35|0.67|0.03|0.71|0.50|1.00|0.73|0.51$1.19|1.45|1.33|0.72|0.44|1.43|1.27|0.74|1.55|0.61|1.36|1.45|1.35|1.20|0.10|1.02|0.82|0.58|1.06|0.46$0.77|1.11|1.39|0.79|0.44|0.95|0.92|2.74|1.65|0.64|0.66|1.19|0.74|1.04|0.66|0.64|0.82|0.58|0.93|0.53$0.93|0.96|0.82|1.15|0.67|1.02|1.07|1.08|1.40|1.14|1.16|1.27|1.11|1.05|1.01|0.71|0.84|1.06|1.15|0.74$1.09|1.29|1.03|1.17|0.26|1.08|1.31|0.97|0.88|0.97|0.87|1.13|0.96|0.84|2.01|0.76|0.79|0.91|0.64|0.77$0.71|1.09|0.95|1.43|0.65|0.87|1.19|1.07|1.13|1.05|0.84|1.10|0.80|0.95|1.70|0.65|.086|1.25|0.85|1.12$13.4|13.3|12.0|11.7|11.6|12.8|12.2|11.3|11.6|12.0|13.0|13.0|12.8|12.1|6.5|12.2|11.7|12.4|12.1|11.9$-0.77|-0.68|-0.07|-0.15|-0.23|-0.33|-0.27|0.00|-0.06|-0.23|-0.62|-0.65|-0.50|-0.41|3|-0.35|-0.11|-0.45|-0.17|-0.14$0.984|1.008|1.048|1.068|0.906|1.037|1.094|1.031|0.950|0.927|0.935|1.102|0.952|0.915|1.049|1.046|0.997|0.904|0.929|0.931$1.315|1.310|1.380|1.372|1.196|1.342|1.376|1.382|1.279|1.241|1.234|1.367|1.269|1.247|1.342|1.381|1.324|1.186|1.199|1.235$0.994|1.026|1.022|1.022|0.939|1.041|1.052|1.018|0.967|0.977|0.982|1.029|0.963|0.934|1.050|1.025|0.998|0.938|0.981|0.968$0.783|0.807|0.799|0.822|0.785|0.817|0.826|0.784|0.777|0.776|0.783|0.834|0.806|0.774|0.809|0.811|0.795|0.796|0.788|0.781$0.423|0.503|0.906|0.870|0.877|0.594|0.167|1.162|0.802|0.566|0.494|0.615|0.444|0.706|1.945|0.928|0.884|0.690|0.778|0.706$0.619|0.753|1.089|0.932|1.107|0.770|0.675|1.361|1.034|0.876|0.740|0.784|0.736|0.968|1.780|0.969|1.053|0.910|1.009|0.939$1.080|0.976|1.197|1.266|0.733|1.050|1.085|1.104|0.906|0.583|0.789|1.026|0.812|0.685|1.412|0.987|0.784|0.755|0.665|0.546$0.978|0.784|0.915|1.038|0.573|0.863|0.962|1.405|0.724|0.502|0.766|0.841|0.729|0.585|2.613|0.784|0.569|0.671|0.560|0.444$1.40|1.23|1.61|1.89|1.14|1.33|1.42|2.06|1.25|1.02|1.33|1.34|1.12|1.07|3.90|1.20|0.99|1.10|0.98|0.87$4.08|3.91|3.83|3.02|4.49|3.67|2.23|4.24|4.08|4.52|4.81|3.77|4.48|5.38|3.80|4.12|4.11|6.10|5.19|4.18$-0.35|-0.44|-0.38|-0.41|-0.47|-0.40|-0.41|0.0|-0.46|-0.56|-0.48|-0.41|-0.46|-0.55|-0.23|-0.39|-0.48|-0.48|-0.50|-0.53$0.5|1.7|1.7|1.6|0.6|1.6|1.6|1.3|1.6|0.6|0.4|1.6|0.5|0.4|1.7|0.7|0.4|0.7|0.6|0.5$0.96|0.77|0.39|0.42|0.42|0.80|0.53|0.00|0.57|0.84|0.92|0.73|0.86|0.59|-2.50|0.53|0.54|0.58|0.72|0.63$0.343|0.353|0.409|0.429|0.319|0.395|0.405|0.389|0.307|0.296|0.287|0.429|0.293|0.292|0.432|0.416|0.362|0.268|0.22|0.307$0.320|0.327|0.384|0.424|0.198|0.436|0.514|0.374|0.299|0.306|0.340|0.446|0.313|0.314|0.354|0.376|0.339|0.291|0.287|0.294$8.9|4.6|4.4|6.3|0.6|2.8|6.9|9.4|2.2|7.0|7.4|6.1|2.3|3.3|4.2|4.0|5.7|1.3|4.5|8.2$9.2|3.6|5.1|6.0|1.0|2.9|6.0|9.4|2.1|6.0|7.7|6.5|2.4|3.4|4.2|5.5|5.7|1.2|3.7|8.2$14.1|5.5|3.2|5.7|0.1|3.7|8.8|4.1|2.0|7.1|9.1|7.7|3.3|5.0|0.7|3.9|4.4|1.2|4.5|5.9$13.4|3.9|3.7|4.6|0.8|4.8|7.8|4.6|3.3|6.5|10.6|7.5|3.0|4.5|1.3|3.8|4.6|1.0|3.3|7.1$9.8|7.3|3.6|4.9|3.0|2.4|4.4|0|11.9|17.2|17.0|10.5|11.9|23.0|15.0|2.6|6.9|24.2|17.2|15.3$0.70|0.95|1.47|0.87|1.17|0.73|0.96|0.64|1.39|1.29|1.44|0.91|0.91|1.34|0.12|0.84|0.74|1.80|1.68|1.20$58|-184|-93|-97|116|-139|-131|-11|-73|107|95|-24|78|92|-79|-34|-7|59|-11|100$51|-144|-84|-78|137|-128|-115|-13|-55|106|103|-205|73|108|-79|-26|-3|69|11|108$41|-109|-74|-47|169|-104|-90|-18|-35|104|103|-148|77|128|-81|-31|10|102|36|116$32|-95|-73|-29|182|-95|-74|-22|-25|106|104|-124|82|132|-82|-34|20|118|44|113$24|-79|-76|0|194|-87|-57|-28|-31|102|103|-9|90|131|-85|-36|34|116|43|111$5|-57|-77|45|224|-67|-8|-47|-50|83|82|-38|83|117|-103|-41|79|130|27|117$-2|-41|-97|248|329|-37|117|-66|-70|28|36|115|62|120|-132|-52|174|179|-7|114$0.4|1.5|1.6|15.|0.7|1.4|1.3|1.1|1.4|0.5|0.3|1.4|0.5|0.3|1.6|0.9|0.7|0.9|0.9|0.4$-0.04|-0.30|0.25|0.27|0.57|-0.02|-0.33|1.24|-0.11|-0.26|-0.38|-0.18|-0.09|-0.01|0.|0.15|0.39|0.21|0.05|-0.06$-0.12|0.34|1.05|1.12|-0.63|1.67|0.91|0.76|1.34|-0.77|0.15|0.29|-0.71|-0.67|0.|1.45|-0.70|-0.14|-0.49|-0.70$8.6|4.2|4.6|4.9|2.9|4.0|5.1|7.8|2.1|4.6|8.8|6.3|2.5|3.7|4.9|7.3|6.0|1.4|3.6|6.7$7.6|5.0|4.4|5.2|2.2|4.1|6.2|6.9|2.1|5.1|9.4|5.8|2.1|4.0|5.4|7.2|6.1|1.4|3.2|6.7$8.1|4.6|3.7|3.8|2.0|3.1|4.6|7.0|2.0|6.7|11.0|4.4|2.8|5.6|4.7|7.3|5.6|1.8|3.3|7.7$7.9|4.9|4.0|5.5|1.9|4.4|7.1|7.1|2.1|5.2|8.6|6.7|2.4|3.9|5.3|6.6|5.3|1.2|3.1|6.8$8.3|8.7|3.7|4.7|1.6|4.7|6.5|6.3|2.1|3.7|7.4|7.9|2.3|2.7|6.9|8.8|5.1|0.7|2.4|5.3$4.47|8.48|3.89|7.05|0.29|2.87|16.56|8.29|1.74|3.30|5.06|12.98|1.71|2.32|5.41|4.27|3.83|0.67|2.75|4.05$6.77|6.87|5.50|8.57|0.31|5.24|12.93|7.95|2.80|2.72|4.43|10.20|1.87|1.92|4.79|5.41|5.36|0.54|2.26|3.57$7.43|4.51|9.12|8.71|0.42|5.42|5.86|9.40|1.49|1.76|2.74|9.67|0.60|1.18|5.60|9.60|8.95|1.18|3.26|3.10$5.22|7.30|6.06|7.91|1.01|6.00|10.66|5.81|2.27|2.36|4.52|12.68|1.85|1.68|5.70|6.99|5.16|0.56|2.16|4.10$9.88|3.71|2.35|3.50|1.12|1.66|4.02|6.88|1.88|10.08|13.21|3.39|2.44|5.27|3.80|4.10|4.98|1.11|4.07|12.53$10.98|3.26|2.85|3.37|1.47|2.30|3.51|7.48|2.20|9.74|12.79|2.54|3.10|4.97|3.42|4.93|5.55|1.28|3.55|10.69$9.95|3.05|4.84|4.46|1.30|2.64|2.58|8.87|1.99|7.73|9.66|2.00|2.45|5.41|3.20|6.03|5.62|2.60|6.15|9.46$8.26|2.80|2.54|2.80|2.67|2.86|2.67|5.62|1.98|8.95|16.46|1.89|2.67|7.32|3.30|6.00|5.00|2.01|3.96|10.24$7.39|5.91|3.06|5.14|0.74|2.22|9.80|7.53|1.82|6.96|9.45|7.81|2.10|3.91|4.54|4.18|4.45|0.90|3.46|8.62$9.07|4.90|4.05|5.73|0.95|3.63|7.77|7.69|2.47|6.56|9.00|6.01|2.54|3.59|4.04|5.15|5.46|0.95|2.96|7.47$8.82|3.71|6.77|6.38|0.90|3.89|4.05|9.11|1.77|5.05|6.54|5.45|1.62|3.51|4.28|7.64|7.12|1.96|4.85|6.60$6.65|5.17|4.40|5.50|1.79|4.52|6.89|5.72|2.13|5.47|10.15|7.59|2.24|4.34|4.56|6.52|5.08|1.24|3.01|7.00$0|2.45|0|0|0|1.25|1.27|0|1.45|0|0|3.67|0|0|0|0|0|6.93|5.06|0$89.3|190.3|122.4|114.4|102.5|146.9|138.8|63.8|157.5|163.0|163.1|165.1|165.8|190.8|121.6|94.2|119.6|226.4|194.6|138.2$90.0|194.0|124.7|117.3|103.3|149.4|142.2|64.9|160.0|163.9|164.0|167.3|167.0|191.9|122.9|95.4|121.5|228.2|197.0|139.0$0.0373|0.0959|0.0036|0.1263|0.0829|0.0761|0.0058|0.0050|0.0242|0.0000|0.0000|0.0371|0.0823|0.0946|0.0198|0.0829|0.0941|0.0548|0.0516|0.0057$0.85|0.20|-0.48|-1.10|2.10|-0.42|-0.79|0|0.22|3.14|1.99|-1.19|1.42|1.69|-1.14|-0.52|-0.08|1.76|1.37|2.53$0.06|-0.85|0.25|-0.20|0.49|0.31|-0.10|0.21|-2.24|3.48|3.50|-1.62|0.21|4.80|0.71|-0.62|0.65|2.29|1.89|1.59$2.62|1.26|-1.27|-2.84|0.73|-1.69|-0.45|-1.15|-0.74|4.38|6.57|-2.78|-3.12|9.14|-0.12|-1.39|1.81|5.91|1.39|2.30$-1.64|-3.28|0.83|0.70|9.30|-0.04|1.18|-1.85|7.17|3.02|0.83|-2.36|4.26|-1.36|3.12|1.59|2.31|2.61|2.37|0.52$-2.34|1.60|2.81|-0.48|5.03|0.16|1.30|-1.06|-3.00|7.26|1.09|1.56|0.62|2.57|-0.15|1.93|0.19|3.59|-2.58|2.06$0.78|1.58|1.20|1.35|0.55|1.19|1.45|0.68|0.99|0.47|0.56|1.10|0.66|0.47|0.69|1.00|1.05|0.70|1.00|0.51$25|-7|-7|2|32|0|14|-2|-26|91|100|-26|68|100|25|-2|7|109|56|62$1.10|-5.10|-3.50|-3.60|2.50|-3.68|-3.20|-0.64|-3.20|4.50|3.80|-4.11|1.90|2.80|-1.90|-0.50|-0.70|-0.46|-1.3|4.2$0.1366|0.0363|-0.0345|-0.1233|0.2745|0.0325|-0.0484|-0.0464|0.0549|0.4172|0.4251|-0.0101|0.1747|0.4076|0.0019|-0.0433|0.0589|0.2362|0.3167|0.4084$0.0728|0.0394|-0.0390|-0.0552|0.3557|0.0126|-0.0295|-0.0589|0.0874|0.3805|0.3819|-0.0053|0.1613|0.4201|-0.0492|-0.0282|0.0239|0.4114|0.3113|0.2947$0.1510|-0.0103|0.0381|0.0047|0.3222|0.0246|-0.0639|0.0248|0.1335|0.4238|0.3926|-0.0158|0.2160|0.3455|0.0844|0.0040|0.1462|0.2657|0.2998|0.3997$-0.058|0.000|0.027|0.016|0.447|-0.073|-0.128|0.331|0.195|0.060|0.138|-0.112|0.275|0.240|-0.478|-0.177|-0.163|0.564|0.322|-0.052$-0.17|0.37|0.18|0.37|-0.06|0.26|0.15|0.01|-0.02|-0.28|-0.28|0.32|-0.26|-0.41|0.13|0.05|0.02|-0.15|-0.09|-0.17$-0.15|0.32|0.22|0.41|-0.15|0.03|0.30|0.08|0.06|-0.29|-0.36|0.24|-0.19|-0.22|0.15|0.16|-0.08|-0.28|-0.03|-0.24$0.964|1.143|0.944|0.916|0.778|1.047|1.051|0.835|1.014|0.922|1.085|0.944|1.032|1.119|1.299|0.947|1.017|0.895|1|0.955$0.974|1.129|0.988|0.892|0.972|1.092|1.054|0.845|0.949|0.928|1.11|0.946|0.923|1.122|1.362|0.932|1.023|0.879|0.902|0.923$0.938|1.137|0.902|0.857|0.6856|0.916|1.139|0.892|1.109|0.986|1|0.952|1.077|1.11|1.266|0.956|1.018|0.971|1.157|0.959$1.042|1.069|0.828|0.97|0.5|1.111|0.992|0.743|1.034|0.852|1.193|0.979|0.998|0.981|1.332|0.984|0.992|0.96|1.12|1.001$1.065|1.131|0.762|0.836|1.015|0.861|0.736|1.022|0.973|1.189|1.192|0.478|1.369|1.368|1.241|1.097|0.822|1.017|0.836|1.14$0.99|1.132|0.873|0.915|0.644|0.999|1.053|0.785|1.054|0.95|1.106|1.003|1.093|1.121|1.314|0.911|0.988|0.939|1.09|0.957$0.892|1.154|1.144|0.925|1.035|1.2|1.115|0.917|0.992|0.817|0.994|0.944|0.782|1.058|1.309|0.986|1.11|0.841|0.866|0.9$1.092|1.239|0.927|0.919|0.662|1.124|1.199|0.698|1.012|0.912|1.276|1.008|1.171|1.09|0.8|0.886|0.832|0.981|1.075|0.908$0.843|1.038|0.956|0.906|0.896|0.968|0.9|0.978|1.05|0.946|0.885|0.893|0.878|1.151|1.816|1.003|1.189|0.852|0.945|0.999$2.18|2.71|1.85|1.75|3.89|2.16|1.89|1.17|2.51|4.50|4.71|2.12|3.63|5.88|2.09|1.66|2.18|6.46|5.01|3.77$1.79|3.20|2.83|2.33|2.22|2.37|2.52|0.70|3.06|4.59|4.72|2.50|3.91|4.84|2.45|1.82|2.45|5.64|4.46|3.67$13.4|8.5|7.6|8.2|22.6|8.5|7.3|7.0|11.3|20.3|20.8|6.1|15.7|23.9|9.9|8.2|10.3|24.5|19.5|19.5$0.0166|-0.0762|-0.0786|-0.1278|0.5724|-0.1051|-0.1794|-0.0442|0.1643|0.2758|0.2523|-0.2134|0.0197|0.3561|-0.4188|-0.1629|-0.0701|0.3836|0.2500|0.1782$90.1|192.8|127.5|117.1|113.2|149.4|140.8|63.8|159.3|164.9|164.6|170.0|167.7|193.5|123.1|94.2|120.0|197.1|231.7|139.1$91.5|196.1|138.3|135.2|114.4|156.4|154.6|67.5|163.2|162.6|163.4|162.5|165.9|198.8|123.4|102.0|126.0|209.8|237.2|138.4$1.076|1.361|1.056|1.290|0.753|0.729|1.118|1.346|0.985|0.926|1.054|1.105|0.974|0.869|0.820|1.342|0.871|0.666|0.531|1.131$1.12|-2.55|-0.83|-0.83|0.59|-0.78|-0.92|1.20|-0.93|1.16|1.18|-0.80|0.55|0.67|0.54|-0.05|-0.02|-0.19|-0.23|1.13$1.38|0.00|0.37|0.52|1.43|0.22|0.71|1.34|0.66|2.32|1.47|0.15|1.78|1.72|0.85|0.86|0.89|0.82|0.47|1.99$-0.27|1.87|0.81|0.81|-1.05|1.10|1.17|-0.16|0.28|-0.77|-1.10|1.70|-0.73|-1.43|-0.75|0.42|0.63|-1.57|-0.56|-0.40$0.05|0.12|0.29|0.41|-0.84|0.46|0.38|0.31|-0.41|-0.69|-0.62|0.57|-0.38|-0.45|0.46|0.12|0.38|-0.98|-0.25|-0.46$-0.31|1.30|0.49|0.58|-0.87|0.70|0.68|-0.33|0.13|-0.66|-0.53|1.79|-0.38|-0.45|0.34|0.10|0.21|-0.27|0.40|-0.62$-0.27|2.00|0.61|0.50|-0.23|1.00|0.33|-0.22|0.37|-0.80|-0.44|1.17|-0.31|-0.55|0.36|0.17|0.18|0.05|0.48|-0.65$0.18|-5.40|-1.30|-2.36|0.27|-1.22|-2.10|0.09|-1.48|0.37|0.41|-2.53|0.44|0.50|-0.20|-0.40|-0.34|-0.01|-0.08|0.32$0.42|-1.56|-1.03|-0.51|0.84|-0.96|-0.37|0.00|-2.28|1.81|1.80|-2.03|1.18|1.74|0.86|-0.64|-0.26|1.46|0.51|1.34$0.616|0.000|0.236|0.028|0.680|0.251|0.043|0.501|0.165|0.943|0.943|0.283|0.738|1.000|0.711|0.359|0.450|0.878|0.880|0.825$0.2|-0.7|-0.5|-1.4|1.9|-1.1|-1.3|-0.1|0.4|1.4|0.5|-1.6|0.5|1.0|-1.0|-0.7|-0.4|1.6|0.5|0.7$50.76|48.66|45.80|43.17|58.74|46.09|43.48|50.27|49.33|57.30|53.89|42.92|52.75|53.45|45.39|47.24|49.26|53.59|51.79|56.12$-0.414|-0.584|-0.916|-1.310|0.162|-0.905|-1.218|-0.684|-0.630|1.237|1.215|-0.670|1.020|1.938|-0.503|-0.563|-0.289|0.514|1.699|0.899$-0.96|0.75|-1.94|-5.68|4.54|-5.30|-3.86|-1.28|-0.62|5.54|6.81|-5.62|4.76|5.06|-4.47|-1.92|-3.99|0.21|3.34|5.39$-0.26|0.08|-0.46|-1.30|0.83|-0.83|-0.73|-0.40|-0.18|1.10|1.52|-1.01|1.09|1.09|-0.62|-0.55|-0.71|-0.13|0.69|1.15$-0.73|-1.03|-5.29|-6.13|0.64|-0.96|-2.90|-2.67|3.03|5.04|4.91|-5.99|3.34|5.20|-4.32|-3.00|-1.91|0.51|2.87|3.98$-1.35|-3.89|-10.96|-11.88|4.37|-1.34|-4.56|-5.82|6.54|10.93|9.88|-11.92|7.47|11.35|-10.86|-6.21|-4.83|1.80|7.61|8.20$-0.56|-0.26|-2.87|-4.31|1.78|-2.31|-2.35|-1.35|0.81|3.83|4.09|-4.08|3.11|3.67|-3.22|-1.85|-1.97|-0.11|2.17|3.31$1.37|1.33|6.29|8.93|-4.47|3.88|4.04|3.39|-1.65|-7.92|-8.68|7.70|-7.13|-7.96|6.25|4.08|4.02|0.79|-4.73|-6.94$-0.02|0.44|0.63|0.72|-0.96|0.56|0.74|0.38|0.00|-1.89|-2.29|1.01|-1.36|-2.22|0.47|0.55|0.25|-1.28|-0.88|-1.34$0.00|0.07|0.10|0.12|-0.16|0.09|0.12|0.06|0.00|-0.31|-0.37|0.17|-0.22|-0.36|0.08|0.09|0.04|-0.21|-0.14|-0.22$-0.03|0.09|0.13|0.17|-0.36|0.13|0.23|0.09|-0.04|-0.33|-0.38|0.32|-0.30|-0.34|0.20|0.10|0.01|-0.24|-0.23|-0.29$-0.04|0.07|0.13|0.19|-0.38|0.14|0.23|0.09|-0.04|-0.34|-0.37|0.33|-0.30|-0.38|0.19|0.12|0.03|-0.33|-0.29|-0.29$-0.02|0.08|0.10|0.19|-0.32|0.15|0.21|-0.02|-0.02|-0.28|-0.32|0.30|-0.25|-0.33|0.11|0.11|0.05|-0.27|-0.23|-0.23$-1.6|12.3|4.8|9.2|-2.0|4.1|8.2|-1.0|3.0|-3.1|-2.8|8.8|-3.4|-3.7|0.2|-0.6|-1.2|-1.9|0.7|-2.6$-0.21|2.11|0.96|1.36|-6.04|1.52|2.30|0.00|-1.23|-4.81|-4.68|3.88|-3.66|-4.65|0.75|1.74|0.78|-3.32|-1.01|-3.50'\n",
    "    AAindexName = AAIN.split('$')\n",
    "    tmp = AAID.split('$')\n",
    "    AAindex = [item.split('|') for item in tmp]\n",
    "\n",
    "    index = {}\n",
    "    for i in range(len(AA)):\n",
    "        index[AA[i]] = i\n",
    "\n",
    "    #  use the user inputed properties\n",
    "    if props:\n",
    "        tmpIndexNames = []\n",
    "        tmpIndex = []\n",
    "        for p in props:\n",
    "            if AAindexName.index(p) != -1:\n",
    "                tmpIndexNames.append(p)\n",
    "                tmpIndex.append(AAindex[AAindexName.index(p)])\n",
    "        if len(tmpIndexNames) != 0:\n",
    "            AAindexName = tmpIndexNames\n",
    "            AAindex = tmpIndex\n",
    "    \n",
    "    header = []\n",
    "    for idName in AAindexName:\n",
    "        header.append(idName)\n",
    "    \n",
    "    encodings = []\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], i[1]\n",
    "        code = []\n",
    "        \n",
    "        for j in AAindex:\n",
    "            tmp = 0\n",
    "            for aa in sequence:\n",
    "                if aa == '-':\n",
    "                    tmp = tmp + 0\n",
    "                else:\n",
    "                    tmp = tmp + float(j[index[aa]])\n",
    "            code.append(tmp/len(sequence))\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "\n",
    "def APAAC(fastas, lambdaValue=30, w=0.05, **kw):\n",
    "    records = []\n",
    "    records.append(\"#   A   R   N   D   C   Q   E   G   H   I   L   K   M   F   P   S   T   W   Y   V\")\n",
    "    records.append(\"Hydrophobicity  0.62    -2.53   -0.78   -0.9    0.29    -0.85   -0.74   0.48    -0.4    1.38    1.06    -1.5    0.64    1.19    0.12    -0.18   -0.05   0.81    0.26    1.08\")\n",
    "    records.append(\"Hydrophilicity  -0.5    3   0.2 3   -1  0.2 3   0   -0.5    -1.8    -1.8    3   -1.3    -2.5    0   0.3 -0.4    -3.4    -2.3    -1.5\")\n",
    "    records.append(\"SideChainMass   15  101 58  59  47  72  73  1   82  57  57  73  75  91  42  31  45  130 107 43\")\n",
    "\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records) - 1):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j - meanI) ** 2 for j in i]) / 20)\n",
    "        AAProperty1.append([(j - meanI) / fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for i in AA:\n",
    "        header.append('Pc1.' + i)\n",
    "    for j in range(1, lambdaValue + 1):\n",
    "        for i in AAPropertyNames:\n",
    "            header.append('Pc2.' + i + '.' + str(j))\n",
    "    \n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        theta = []\n",
    "\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            for j in range(len(AAProperty1)):\n",
    "                theta.append(sum([AAProperty1[j][AADict[sequence[k]]] * AAProperty1[j][AADict[sequence[k + n]]] for k in\n",
    "                                  range(len(sequence) - n)]) / (len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [w * value / (1 + w * sum(theta)) for value in theta]\n",
    "\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "def Count(seq1, seq2):\n",
    "    sum = 0\n",
    "    for aa in seq1:\n",
    "        sum = sum + seq2.count(aa)\n",
    "    return sum\n",
    "\n",
    "def PCP(fastas, **kw): \n",
    "    groups = {\n",
    "        'charged':'DEKHR',\n",
    "        'aliphatic':'ILV',\n",
    "        'aromatic':'FHWY',\n",
    "        'polar':'DERKQN',\n",
    "        'neutral':'AGHPSTY',\n",
    "        'hydrophobic':'CVLIMFW',\n",
    "        'positively-charged':'HKR',\n",
    "        'negatively-charged':'DE',\n",
    "        'tiny':'ACDGST',\n",
    "        'small':'EHILKMNPQV',\n",
    "        'large':'FRWY'\n",
    "    }\n",
    "\n",
    "\n",
    "    property = (\n",
    "    'charged', 'aliphatic', 'aromatic', 'polar',\n",
    "    'neutral', 'hydrophobic', 'positively-charged', 'negatively-charged',\n",
    "    'tiny', 'small', 'large')\n",
    "\n",
    "    encodings = []\n",
    "    header = property\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            c = Count(groups[p], sequence) / len(sequence)\n",
    "            code = code + [c]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), list(header)\n",
    "\n",
    "def CTDC(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for g in range(1, len(groups) + 1):\n",
    "            header.append(p + '.G' + str(g))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            c1 = Count(group1[p], sequence) / len(sequence)\n",
    "            c2 = Count(group2[p], sequence) / len(sequence)\n",
    "            c3 = 1 - c1 - c2\n",
    "            code = code + [c1, c2, c3]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "def Count2(aaSet, sequence):\n",
    "    number = 0\n",
    "    for aa in sequence:\n",
    "        if aa in aaSet:\n",
    "            number = number + 1\n",
    "    cutoffNums = [1, math.floor(0.25 * number), math.floor(0.50 * number), math.floor(0.75 * number), number]\n",
    "    cutoffNums = [i if i >=1 else 1 for i in cutoffNums]\n",
    "\n",
    "    code = []\n",
    "    for cutoff in cutoffNums:\n",
    "        myCount = 0\n",
    "        for i in range(len(sequence)):\n",
    "            if sequence[i] in aaSet:\n",
    "                myCount += 1\n",
    "                if myCount == cutoff:\n",
    "                    code.append((i + 1) / len(sequence) * 100)\n",
    "                    break\n",
    "        if myCount == 0:\n",
    "            code.append(0)\n",
    "    return code\n",
    "\n",
    "def CTDD(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for g in ('1', '2', '3'):\n",
    "            for d in ['0', '25', '50', '75', '100']:\n",
    "                header.append(p + '.' + g + '.residue' + d)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence  = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        for p in property:\n",
    "            code = code + Count2(group1[p], sequence) + Count2(group2[p], sequence) + Count2(group3[p], sequence)\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "def CTDT(fastas, **kw):\n",
    "    group1 = {\n",
    "        'hydrophobicity_PRAM900101': 'RKEDQN',\n",
    "        'hydrophobicity_ARGP820101': 'QSTNGDE',\n",
    "        'hydrophobicity_ZIMJ680101': 'QNGSWTDERA',\n",
    "        'hydrophobicity_PONP930101': 'KPDESNQT',\n",
    "        'hydrophobicity_CASG920101': 'KDEQPSRNTG',\n",
    "        'hydrophobicity_ENGD860101': 'RDKENQHYP',\n",
    "        'hydrophobicity_FASG890101': 'KERSQD',\n",
    "        'normwaalsvolume': 'GASTPDC',\n",
    "        'polarity':        'LIFWCMVY',\n",
    "        'polarizability':  'GASDT',\n",
    "        'charge':          'KR',\n",
    "        'secondarystruct': 'EALMQKRH',\n",
    "        'solventaccess':   'ALFCGIVW'\n",
    "    }\n",
    "    group2 = {\n",
    "        'hydrophobicity_PRAM900101': 'GASTPHY',\n",
    "        'hydrophobicity_ARGP820101': 'RAHCKMV',\n",
    "        'hydrophobicity_ZIMJ680101': 'HMCKV',\n",
    "        'hydrophobicity_PONP930101': 'GRHA',\n",
    "        'hydrophobicity_CASG920101': 'AHYMLV',\n",
    "        'hydrophobicity_ENGD860101': 'SGTAW',\n",
    "        'hydrophobicity_FASG890101': 'NTPG',\n",
    "        'normwaalsvolume': 'NVEQIL',\n",
    "        'polarity':        'PATGS',\n",
    "        'polarizability':  'CPNVEQIL',\n",
    "        'charge':          'ANCQGHILMFPSTWYV',\n",
    "        'secondarystruct': 'VIYCWFT',\n",
    "        'solventaccess':   'RKQEND'\n",
    "    }\n",
    "    group3 = {\n",
    "        'hydrophobicity_PRAM900101': 'CLVIMFW',\n",
    "        'hydrophobicity_ARGP820101': 'LYPFIW',\n",
    "        'hydrophobicity_ZIMJ680101': 'LPFYI',\n",
    "        'hydrophobicity_PONP930101': 'YMFWLCVI',\n",
    "        'hydrophobicity_CASG920101': 'FIWC',\n",
    "        'hydrophobicity_ENGD860101': 'CVLIMF',\n",
    "        'hydrophobicity_FASG890101': 'AYHWVMFLIC',\n",
    "        'normwaalsvolume': 'MHKFRYW',\n",
    "        'polarity':        'HQRKNED',\n",
    "        'polarizability':  'KMHFRYW',\n",
    "        'charge':          'DE',\n",
    "        'secondarystruct': 'GNPSD',\n",
    "        'solventaccess':   'MSPTHY'\n",
    "    }\n",
    "\n",
    "    groups = [group1, group2, group3]\n",
    "    property = (\n",
    "    'hydrophobicity_PRAM900101', 'hydrophobicity_ARGP820101', 'hydrophobicity_ZIMJ680101', 'hydrophobicity_PONP930101',\n",
    "    'hydrophobicity_CASG920101', 'hydrophobicity_ENGD860101', 'hydrophobicity_FASG890101', 'normwaalsvolume',\n",
    "    'polarity', 'polarizability', 'charge', 'secondarystruct', 'solventaccess')\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for p in property:\n",
    "        for tr in ('Tr1221', 'Tr1331', 'Tr2332'):\n",
    "            header.append(p + '.' + tr)\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        aaPair = [sequence[j:j + 2] for j in range(len(sequence) - 1)]\n",
    "        for p in property:\n",
    "            c1221, c1331, c2332 = 0, 0, 0\n",
    "            for pair in aaPair:\n",
    "                if (pair[0] in group1[p] and pair[1] in group2[p]) or (pair[0] in group2[p] and pair[1] in group1[p]):\n",
    "                    c1221 = c1221 + 1\n",
    "                    continue\n",
    "                if (pair[0] in group1[p] and pair[1] in group3[p]) or (pair[0] in group3[p] and pair[1] in group1[p]):\n",
    "                    c1331 = c1331 + 1\n",
    "                    continue\n",
    "                if (pair[0] in group2[p] and pair[1] in group3[p]) or (pair[0] in group3[p] and pair[1] in group2[p]):\n",
    "                    c2332 = c2332 + 1\n",
    "            code = code + [c1221/len(aaPair), c1331/len(aaPair), c2332/len(aaPair)]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "def DPC(fastas, gap, **kw):\n",
    "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    encodings = []\n",
    "    diPeptides = [aa1 + aa2 for aa1 in AA for aa2 in AA]\n",
    "    header = [] + diPeptides\n",
    "\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence = i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        tmpCode = [0] * 400\n",
    "        for j in range(len(sequence) - 2 + 1 - gap):\n",
    "            tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+gap+1]]] = tmpCode[AADict[sequence[j]] * 20 + AADict[sequence[j+gap+1]]] +1\n",
    "        if sum(tmpCode) != 0:\n",
    "            tmpCode = [i/sum(tmpCode) for i in tmpCode]\n",
    "        code = code + tmpCode\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "def Rvalue(aa1, aa2, AADict, Matrix):\n",
    "    return sum([(Matrix[i][AADict[aa1]] - Matrix[i][AADict[aa2]]) ** 2 for i in range(len(Matrix))]) / len(Matrix)\n",
    "\n",
    "\n",
    "def PAAC(fastas, lambdaValue=30, w=0.05, **kw):\n",
    "    records = []\n",
    "    records.append(\"#   A   R   N   D   C   Q   E   G   H   I   L   K   M   F   P   S   T   W   Y   V\")\n",
    "    records.append(\"Hydrophobicity  0.62    -2.53   -0.78   -0.9    0.29    -0.85   -0.74   0.48    -0.4    1.38    1.06    -1.5    0.64    1.19    0.12    -0.18   -0.05   0.81    0.26    1.08\")\n",
    "    records.append(\"Hydrophilicity  -0.5    3   0.2 3   -1  0.2 3   0   -0.5    -1.8    -1.8    3   -1.3    -2.5    0   0.3 -0.4    -3.4    -2.3    -1.5\")\n",
    "    records.append(\"SideChainMass   15  101 58  59  47  72  73  1   82  57  57  73  75  91  42  31  45  130 107 43\")\n",
    "    AA = ''.join(records[0].rstrip().split()[1:])\n",
    "    AADict = {}\n",
    "    for i in range(len(AA)):\n",
    "        AADict[AA[i]] = i\n",
    "    AAProperty = []\n",
    "    AAPropertyNames = []\n",
    "    for i in range(1, len(records)):\n",
    "        array = records[i].rstrip().split() if records[i].rstrip() != '' else None\n",
    "        AAProperty.append([float(j) for j in array[1:]])\n",
    "        AAPropertyNames.append(array[0])\n",
    "\n",
    "    AAProperty1 = []\n",
    "    for i in AAProperty:\n",
    "        meanI = sum(i) / 20\n",
    "        fenmu = math.sqrt(sum([(j - meanI) ** 2 for j in i]) / 20)\n",
    "        AAProperty1.append([(j - meanI) / fenmu for j in i])\n",
    "\n",
    "    encodings = []\n",
    "    header = []\n",
    "    for aa in AA:\n",
    "        header.append('Xc1.' + aa)\n",
    "    for n in range(1, lambdaValue + 1):\n",
    "        header.append('Xc2.lambda' + str(n))\n",
    "\n",
    "    for i in fastas:\n",
    "        name, sequence= i[0], re.sub('-', '', i[1])\n",
    "        code = []\n",
    "        theta = []\n",
    "        for n in range(1, lambdaValue + 1):\n",
    "            theta.append(\n",
    "                sum([Rvalue(sequence[j], sequence[j + n], AADict, AAProperty1) for j in range(len(sequence) - n)]) / (\n",
    "                    len(sequence) - n))\n",
    "        myDict = {}\n",
    "        for aa in AA:\n",
    "            myDict[aa] = sequence.count(aa)\n",
    "        code = code + [myDict[aa] / (1 + w * sum(theta)) for aa in AA]\n",
    "        code = code + [(w * j) / (1 + w * sum(theta)) for j in theta]\n",
    "        encodings.append(code)\n",
    "    return np.array(encodings, dtype=float), header\n",
    "\n",
    "def reducedACID(seq):\n",
    "    def fcount(string, substr):\n",
    "       count = 0\n",
    "       pos = 0\n",
    "       while(True):\n",
    "           pos = string.find(substr , pos)\n",
    "           if pos > -1:\n",
    "               count = count + 1\n",
    "               pos += 1\n",
    "           else:\n",
    "               break\n",
    "       return count\n",
    "\n",
    "    for count, fasta in enumerate(seq):\n",
    "        sub = \"akn\"\n",
    "        subsub = [it1+it2 for it1 in sub for it2 in sub] \n",
    "        aalist = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        aasub = {}\n",
    "        aasub[\"a\"] = \"DE\"\n",
    "        aasub[\"k\"] = \"KHR\"\n",
    "        aasub[\"n\"] = \"ACFGILMNPQSTVWY\"\n",
    "        \n",
    "        seq1 = fasta[1]\n",
    "        lenn=len(seq1)\n",
    "        seq2 = seq1\n",
    "        for key, value in aasub.items():\n",
    "            for aa in value:\n",
    "                seq2 = seq2.replace(aa,key)\n",
    "        \n",
    "        freq2 = {}\n",
    "        for item in sub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "        for item in subsub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "            \n",
    "        freq1 = {}\n",
    "        for item in aalist:\n",
    "            freq1[item] = fcount(seq1, item)\n",
    "            \n",
    "        feat = []\n",
    "        for key, value in aasub.items():\n",
    "            feat.append(freq2[key]/lenn)\n",
    "            \n",
    "        for item in aalist:\n",
    "            for key, value in aasub.items():\n",
    "                if item in value:\n",
    "                    feat.append(freq1[item]/max(1,freq2[key]))\n",
    "                    break\n",
    "                    \n",
    "        for item in subsub:\n",
    "            feat.append(freq2[item]/(freq2[item[0]]+1))\n",
    "        \n",
    "        feat = np.array(feat)\n",
    "        feat = feat.reshape(1,len(feat))\n",
    "        if count == 0:\n",
    "            allfeat = feat\n",
    "        else:\n",
    "            allfeat = np.vstack((allfeat, feat))\n",
    "            \n",
    "    return allfeat\n",
    "\"\"\"\n",
    "Polarity/acidity DE RHK WYF SCMNQT GAVLIP\n",
    "Acidity DE KHR ACFGILMNPQSTVWY\n",
    "Secondary structure EHALMQKR VTIYCWF GDNPS\n",
    "Charge KR AVNCQGHILMFPSTWY DE\n",
    "DHP PALVIFWM QSTYCNG HKR DE\n",
    "\"\"\"\n",
    "def reducedPOLAR(seq):\n",
    "    def fcount(string, substr):\n",
    "       count = 0\n",
    "       pos = 0\n",
    "       while(True):\n",
    "           pos = string.find(substr , pos)\n",
    "           if pos > -1:\n",
    "               count = count + 1\n",
    "               pos += 1\n",
    "           else:\n",
    "               break\n",
    "       return count\n",
    "\n",
    "    for count, fasta in enumerate(seq):\n",
    "        sub = \"qwert\"\n",
    "        subsub = [it1+it2 for it1 in sub for it2 in sub] \n",
    "        aalist = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        aasub = {}\n",
    "        aasub[\"q\"] = \"DE\"\n",
    "        aasub[\"w\"] = \"RHK\"\n",
    "        aasub[\"e\"] = \"WYF\"\n",
    "        aasub[\"r\"] = \"SCMNQT\"\n",
    "        aasub[\"t\"] = \"GAVLIP\"\n",
    "        \n",
    "        seq1 = fasta[1]\n",
    "        lenn=len(seq1)\n",
    "        seq2 = seq1\n",
    "        for key, value in aasub.items():\n",
    "            for aa in value:\n",
    "                seq2 = seq2.replace(aa,key)\n",
    "        \n",
    "        freq2 = {}\n",
    "        for item in sub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "        for item in subsub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "            \n",
    "        freq1 = {}\n",
    "        for item in aalist:\n",
    "            freq1[item] = fcount(seq1, item)\n",
    "            \n",
    "        feat = []\n",
    "        for key, value in aasub.items():\n",
    "            feat.append(freq2[key]/lenn)\n",
    "            \n",
    "        for item in aalist:\n",
    "            for key, value in aasub.items():\n",
    "                if item in value:\n",
    "                    feat.append(freq1[item]/max(1,freq2[key]))\n",
    "                    break\n",
    "                    \n",
    "        for item in subsub:\n",
    "            feat.append(freq2[item]/(freq2[item[0]]+1))\n",
    "        \n",
    "        feat = np.array(feat)\n",
    "        feat = feat.reshape(1,len(feat))\n",
    "        if count == 0:\n",
    "            allfeat = feat\n",
    "        else:\n",
    "            allfeat = np.vstack((allfeat, feat))\n",
    "            \n",
    "    return allfeat\n",
    "\n",
    "def reducedSECOND(seq):\n",
    "    def fcount(string, substr):\n",
    "       count = 0\n",
    "       pos = 0\n",
    "       while(True):\n",
    "           pos = string.find(substr , pos)\n",
    "           if pos > -1:\n",
    "               count = count + 1\n",
    "               pos += 1\n",
    "           else:\n",
    "               break\n",
    "       return count\n",
    "\n",
    "    for count, fasta in enumerate(seq):\n",
    "        sub = \"qwe\"\n",
    "        subsub = [it1+it2 for it1 in sub for it2 in sub] \n",
    "        aalist = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        aasub = {}\n",
    "        aasub[\"q\"] = \"EHALMQKR\"\n",
    "        aasub[\"w\"] = \"VTIYCWF\"\n",
    "        aasub[\"e\"] = \"GDNPS\"\n",
    "        \n",
    "        seq1 = fasta[1]\n",
    "        lenn=len(seq1)\n",
    "        seq2 = seq1\n",
    "        for key, value in aasub.items():\n",
    "            for aa in value:\n",
    "                seq2 = seq2.replace(aa,key)\n",
    "        \n",
    "        freq2 = {}\n",
    "        for item in sub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "        for item in subsub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "            \n",
    "        freq1 = {}\n",
    "        for item in aalist:\n",
    "            freq1[item] = fcount(seq1, item)\n",
    "            \n",
    "        feat = []\n",
    "        for key, value in aasub.items():\n",
    "            feat.append(freq2[key]/lenn)\n",
    "            \n",
    "        for item in aalist:\n",
    "            for key, value in aasub.items():\n",
    "                if item in value:\n",
    "                    feat.append(freq1[item]/max(1,freq2[key]))\n",
    "                    break\n",
    "                    \n",
    "        for item in subsub:\n",
    "            feat.append(freq2[item]/(freq2[item[0]]+1))\n",
    "        \n",
    "        feat = np.array(feat)\n",
    "        feat = feat.reshape(1,len(feat))\n",
    "        if count == 0:\n",
    "            allfeat = feat\n",
    "        else:\n",
    "            allfeat = np.vstack((allfeat, feat))\n",
    "            \n",
    "    return allfeat\n",
    "\n",
    "def reducedCHARGE(seq):\n",
    "    def fcount(string, substr):\n",
    "       count = 0\n",
    "       pos = 0\n",
    "       while(True):\n",
    "           pos = string.find(substr , pos)\n",
    "           if pos > -1:\n",
    "               count = count + 1\n",
    "               pos += 1\n",
    "           else:\n",
    "               break\n",
    "       return count\n",
    "\n",
    "    for count, fasta in enumerate(seq):\n",
    "        sub = \"qwe\"\n",
    "        subsub = [it1+it2 for it1 in sub for it2 in sub] \n",
    "        aalist = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        aasub = {}\n",
    "        aasub[\"q\"] = \"KR\"\n",
    "        aasub[\"w\"] = \"AVNCQGHILMFPSTWY\"\n",
    "        aasub[\"e\"] = \"DE\"\n",
    "        \n",
    "        seq1 = fasta[1]\n",
    "        lenn=len(seq1)\n",
    "        seq2 = seq1\n",
    "        for key, value in aasub.items():\n",
    "            for aa in value:\n",
    "                seq2 = seq2.replace(aa,key)\n",
    "        \n",
    "        freq2 = {}\n",
    "        for item in sub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "        for item in subsub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "            \n",
    "        freq1 = {}\n",
    "        for item in aalist:\n",
    "            freq1[item] = fcount(seq1, item)\n",
    "            \n",
    "        feat = []\n",
    "        for key, value in aasub.items():\n",
    "            feat.append(freq2[key]/lenn)\n",
    "            \n",
    "        for item in aalist:\n",
    "            for key, value in aasub.items():\n",
    "                if item in value:\n",
    "                    feat.append(freq1[item]/max(1,freq2[key]))\n",
    "                    break\n",
    "                    \n",
    "        for item in subsub:\n",
    "            feat.append(freq2[item]/(freq2[item[0]]+1))\n",
    "        \n",
    "        feat = np.array(feat)\n",
    "        feat = feat.reshape(1,len(feat))\n",
    "        if count == 0:\n",
    "            allfeat = feat\n",
    "        else:\n",
    "            allfeat = np.vstack((allfeat, feat))\n",
    "            \n",
    "    return allfeat\n",
    "\n",
    "def reducedDHP(seq):\n",
    "    def fcount(string, substr):\n",
    "       count = 0\n",
    "       pos = 0\n",
    "       while(True):\n",
    "           pos = string.find(substr , pos)\n",
    "           if pos > -1:\n",
    "               count = count + 1\n",
    "               pos += 1\n",
    "           else:\n",
    "               break\n",
    "       return count\n",
    "\n",
    "    for count, fasta in enumerate(seq):\n",
    "        sub = \"qwer\"\n",
    "        subsub = [it1+it2 for it1 in sub for it2 in sub] \n",
    "        aalist = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        aasub = {} \n",
    "        aasub[\"q\"] = \"PALVIFWM\"\n",
    "        aasub[\"w\"] = \"QSTYCNG\"\n",
    "        aasub[\"e\"] = \"HKR\"\n",
    "        aasub[\"r\"] = \"DE\"\n",
    "        \n",
    "        seq1 = fasta[1]\n",
    "        lenn=len(seq1)\n",
    "        seq2 = seq1\n",
    "        for key, value in aasub.items():\n",
    "            for aa in value:\n",
    "                seq2 = seq2.replace(aa,key)\n",
    "        \n",
    "        freq2 = {}\n",
    "        for item in sub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "        for item in subsub:\n",
    "            freq2[item] = fcount(seq2, item)\n",
    "            \n",
    "        freq1 = {}\n",
    "        for item in aalist:\n",
    "            freq1[item] = fcount(seq1, item)\n",
    "            \n",
    "        feat = []\n",
    "        for key, value in aasub.items():\n",
    "            feat.append(freq2[key]/lenn)\n",
    "            \n",
    "        for item in aalist:\n",
    "            for key, value in aasub.items():\n",
    "                if item in value:\n",
    "                    feat.append(freq1[item]/max(1,freq2[key]))\n",
    "                    break\n",
    "                    \n",
    "        for item in subsub:\n",
    "            feat.append(freq2[item]/(freq2[item[0]]+1))\n",
    "        \n",
    "        feat = np.array(feat)\n",
    "        feat = feat.reshape(1,len(feat))\n",
    "        if count == 0:\n",
    "            allfeat = feat\n",
    "        else:\n",
    "            allfeat = np.vstack((allfeat, feat))\n",
    "            \n",
    "    return allfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e9b872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.415746Z",
     "iopub.status.busy": "2024-09-20T06:47:16.415286Z",
     "iopub.status.idle": "2024-09-20T06:47:16.429406Z",
     "shell.execute_reply": "2024-09-20T06:47:16.428089Z"
    },
    "papermill": {
     "duration": 0.027918,
     "end_time": "2024-09-20T06:47:16.432332",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.404414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def featex(fasta):\n",
    "    fname = []\n",
    "    feat0 = reducedACID(fasta); fname.append('reducedACID')\n",
    "    feat1 = reducedPOLAR(fasta); fname.append('reducedPOLAR')\n",
    "    feat2 = reducedSECOND(fasta); fname.append('reducedSECOND')\n",
    "    feat3 = reducedCHARGE(fasta); fname.append('reducedCHARGE')\n",
    "    feat4 = reducedDHP(fasta); fname.append('reducedDHP')\n",
    "    feat5 = AAC(fasta)[0]; fname.append('AAC')\n",
    "    feat6 = DPC(fasta, 0)[0]; fname.append('DPC')\n",
    "    feat7 = np.hstack((CTDC(fasta)[0], CTDD(fasta)[0], CTDT(fasta)[0])); fname.append('CTD')\n",
    "    feat8 = PAAC(fasta, 1)[0]; fname.append('PAAC')\n",
    "    feat9 = APAAC(fasta, 1)[0]; fname.append('APAAC')\n",
    "    feat10 = PCP(fasta)[0]; fname.append('PCP')\n",
    "    feat11 = AAINDEX(fasta)[0]; fname.append('AAINDEX')\n",
    "\n",
    "    allfeat_pos = np.hstack((\n",
    "                             feat0, \n",
    "                             feat1,\n",
    "                             feat2,\n",
    "                             feat3,\n",
    "                             feat4,\n",
    "                             feat5,\n",
    "                             feat6,\n",
    "                             feat7,\n",
    "                             feat8,\n",
    "                             feat9,\n",
    "                             feat10,\n",
    "                             feat11\n",
    "                            ))\n",
    "\n",
    "    numdesc = len(fname)\n",
    "    f = []\n",
    "    before = 0\n",
    "    for i in range(numdesc):\n",
    "        after = before + eval('feat%d.shape[1]' % (i))\n",
    "        f.append(list(range(before, after)))\n",
    "        before = after\n",
    "\n",
    "    return allfeat_pos, f, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b153793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.453543Z",
     "iopub.status.busy": "2024-09-20T06:47:16.453070Z",
     "iopub.status.idle": "2024-09-20T06:47:16.463674Z",
     "shell.execute_reply": "2024-09-20T06:47:16.462262Z"
    },
    "papermill": {
     "duration": 0.024434,
     "end_time": "2024-09-20T06:47:16.466648",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.442214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read protein sequences from FASTA files (input)\n",
    "fasta_new = read_protein_sequences('/kaggle/input/ga-xgb-xgb/test_model.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002996d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.487028Z",
     "iopub.status.busy": "2024-09-20T06:47:16.486576Z",
     "iopub.status.idle": "2024-09-20T06:47:16.592452Z",
     "shell.execute_reply": "2024-09-20T06:47:16.591197Z"
    },
    "papermill": {
     "duration": 0.119473,
     "end_time": "2024-09-20T06:47:16.595425",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.475952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature extraction from new protein sequences\n",
    "feat_new, f, fname = featex(fasta_new)\n",
    "allclass_feat_new = np.hstack((np.ones(len(feat_new))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f6f1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.615865Z",
     "iopub.status.busy": "2024-09-20T06:47:16.615430Z",
     "iopub.status.idle": "2024-09-20T06:47:16.624442Z",
     "shell.execute_reply": "2024-09-20T06:47:16.622999Z"
    },
    "papermill": {
     "duration": 0.022345,
     "end_time": "2024-09-20T06:47:16.627158",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.604813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(feat_new)\n",
    "feat_new_scaled = scaler.transform(feat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ec4f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.647412Z",
     "iopub.status.busy": "2024-09-20T06:47:16.646966Z",
     "iopub.status.idle": "2024-09-20T06:47:16.653929Z",
     "shell.execute_reply": "2024-09-20T06:47:16.652643Z"
    },
    "papermill": {
     "duration": 0.02026,
     "end_time": "2024-09-20T06:47:16.656659",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.636399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine features with labels for saving to CSV\n",
    "df_feat_new = pd.DataFrame(np.hstack((feat_new_scaled, allclass_feat_new.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7db3fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.677136Z",
     "iopub.status.busy": "2024-09-20T06:47:16.676693Z",
     "iopub.status.idle": "2024-09-20T06:47:16.687405Z",
     "shell.execute_reply": "2024-09-20T06:47:16.686167Z"
    },
    "papermill": {
     "duration": 0.023821,
     "end_time": "2024-09-20T06:47:16.689892",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.666071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create column names based on descriptors and ranges\n",
    "column_names = []\n",
    "for i, desc in enumerate(fname):\n",
    "    num_features = len(f[i])\n",
    "    column_names.extend([f\"{desc}{j + 1}\" for j in range(num_features)])\n",
    "column_names.append('label')  # Add 'label' column name\n",
    "\n",
    "# Rename columns in dataframes\n",
    "df_feat_new.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2725a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:16.710246Z",
     "iopub.status.busy": "2024-09-20T06:47:16.709751Z",
     "iopub.status.idle": "2024-09-20T06:47:17.354960Z",
     "shell.execute_reply": "2024-09-20T06:47:17.353728Z"
    },
    "papermill": {
     "duration": 0.658882,
     "end_time": "2024-09-20T06:47:17.357894",
     "exception": false,
     "start_time": "2024-09-20T06:47:16.699012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a182ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:17.378488Z",
     "iopub.status.busy": "2024-09-20T06:47:17.377916Z",
     "iopub.status.idle": "2024-09-20T06:47:18.716497Z",
     "shell.execute_reply": "2024-09-20T06:47:18.715275Z"
    },
    "papermill": {
     "duration": 1.351925,
     "end_time": "2024-09-20T06:47:18.719299",
     "exception": false,
     "start_time": "2024-09-20T06:47:17.367374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the data\n",
    "# Load the feature data\n",
    "feature_tr = pd.read_csv('/kaggle/input/ga-xgb-xgb/X-3.csv')\n",
    "feature_ts = df_feat_new\n",
    "data = pd.read_csv('/kaggle/input/ga-xgb-xgb/X-3.csv')\n",
    "\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = feature_tr.iloc[:, :-1]\n",
    "y_train = feature_tr.iloc[:, -1]\n",
    "X_test = feature_ts.iloc[:, :-1]\n",
    "y_test = feature_ts.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffa2549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:47:18.740593Z",
     "iopub.status.busy": "2024-09-20T06:47:18.740118Z",
     "iopub.status.idle": "2024-09-20T06:48:48.923726Z",
     "shell.execute_reply": "2024-09-20T06:48:48.921934Z"
    },
    "papermill": {
     "duration": 90.1998,
     "end_time": "2024-09-20T06:48:48.928456",
     "exception": false,
     "start_time": "2024-09-20T06:47:18.728656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define descriptor feature groups\n",
    "descriptor_groups = {\n",
    "    'aac': ['AAC1', 'AAC2', 'AAC3', 'AAC4', 'AAC5', 'AAC6', 'AAC7', 'AAC8', 'AAC9', 'AAC10', 'AAC11', 'AAC12', 'AAC13', 'AAC14', 'AAC15', 'AAC16', 'AAC17', 'AAC18', 'AAC19', 'AAC20'],\n",
    "    'pcp': ['PCP1', 'PCP2', 'PCP3', 'PCP4', 'PCP5', 'PCP6', 'PCP7', 'PCP8', 'PCP9', 'PCP10', 'PCP11'],\n",
    "    'aaindex': ['AAINDEX1', 'AAINDEX2', 'AAINDEX3', 'AAINDEX4', 'AAINDEX5', 'AAINDEX6', 'AAINDEX7', 'AAINDEX8', 'AAINDEX9', 'AAINDEX10', 'AAINDEX11', 'AAINDEX12', 'AAINDEX13', 'AAINDEX14', 'AAINDEX15', 'AAINDEX16', 'AAINDEX17', 'AAINDEX18', 'AAINDEX19', 'AAINDEX20', 'AAINDEX21', 'AAINDEX22', 'AAINDEX23', 'AAINDEX24', 'AAINDEX25', 'AAINDEX26', 'AAINDEX27', 'AAINDEX28', 'AAINDEX29', 'AAINDEX30', 'AAINDEX31', 'AAINDEX32', 'AAINDEX33', 'AAINDEX34', 'AAINDEX35', 'AAINDEX36', 'AAINDEX37', 'AAINDEX38', 'AAINDEX39', 'AAINDEX40', 'AAINDEX41', 'AAINDEX42', 'AAINDEX43', 'AAINDEX44', 'AAINDEX45', 'AAINDEX46', 'AAINDEX47', 'AAINDEX48', 'AAINDEX49', 'AAINDEX50', 'AAINDEX51', 'AAINDEX52', 'AAINDEX53', 'AAINDEX54', 'AAINDEX55', 'AAINDEX56', 'AAINDEX57', 'AAINDEX58', 'AAINDEX59', 'AAINDEX60', 'AAINDEX61', 'AAINDEX62', 'AAINDEX63', 'AAINDEX64', 'AAINDEX65', 'AAINDEX66', 'AAINDEX67', 'AAINDEX68', 'AAINDEX69', 'AAINDEX70', 'AAINDEX71', 'AAINDEX72', 'AAINDEX73', 'AAINDEX74', 'AAINDEX75', 'AAINDEX76', 'AAINDEX77', 'AAINDEX78', 'AAINDEX79', 'AAINDEX80', 'AAINDEX81', 'AAINDEX82', 'AAINDEX83', 'AAINDEX84', 'AAINDEX85', 'AAINDEX86', 'AAINDEX87', 'AAINDEX88', 'AAINDEX89', 'AAINDEX90', 'AAINDEX91', 'AAINDEX92', 'AAINDEX93', 'AAINDEX94', 'AAINDEX95', 'AAINDEX96', 'AAINDEX97', 'AAINDEX98', 'AAINDEX99', 'AAINDEX100', 'AAINDEX101', 'AAINDEX102', 'AAINDEX103', 'AAINDEX104', 'AAINDEX105', 'AAINDEX106', 'AAINDEX107', 'AAINDEX108', 'AAINDEX109', 'AAINDEX110', 'AAINDEX111', 'AAINDEX112', 'AAINDEX113', 'AAINDEX114', 'AAINDEX115', 'AAINDEX116', 'AAINDEX117', 'AAINDEX118', 'AAINDEX119', 'AAINDEX120', 'AAINDEX121', 'AAINDEX122', 'AAINDEX123', 'AAINDEX124', 'AAINDEX125', 'AAINDEX126', 'AAINDEX127', 'AAINDEX128', 'AAINDEX129', 'AAINDEX130', 'AAINDEX131', 'AAINDEX132', 'AAINDEX133', 'AAINDEX134', 'AAINDEX135', 'AAINDEX136', 'AAINDEX137', 'AAINDEX138', 'AAINDEX139', 'AAINDEX140', 'AAINDEX141', 'AAINDEX142', 'AAINDEX143', 'AAINDEX144', 'AAINDEX145', 'AAINDEX146', 'AAINDEX147', 'AAINDEX148', 'AAINDEX149', 'AAINDEX150', 'AAINDEX151', 'AAINDEX152', 'AAINDEX153', 'AAINDEX154', 'AAINDEX155', 'AAINDEX156', 'AAINDEX157', 'AAINDEX158', 'AAINDEX159', 'AAINDEX160', 'AAINDEX161', 'AAINDEX162', 'AAINDEX163', 'AAINDEX164', 'AAINDEX165', 'AAINDEX166', 'AAINDEX167', 'AAINDEX168', 'AAINDEX169', 'AAINDEX170', 'AAINDEX171', 'AAINDEX172', 'AAINDEX173', 'AAINDEX174', 'AAINDEX175', 'AAINDEX176', 'AAINDEX177', 'AAINDEX178', 'AAINDEX179', 'AAINDEX180', 'AAINDEX181', 'AAINDEX182', 'AAINDEX183', 'AAINDEX184', 'AAINDEX185', 'AAINDEX186', 'AAINDEX187', 'AAINDEX188', 'AAINDEX189', 'AAINDEX190', 'AAINDEX191', 'AAINDEX192', 'AAINDEX193', 'AAINDEX194', 'AAINDEX195', 'AAINDEX196', 'AAINDEX197', 'AAINDEX198', 'AAINDEX199', 'AAINDEX200', 'AAINDEX201', 'AAINDEX202', 'AAINDEX203', 'AAINDEX204', 'AAINDEX205', 'AAINDEX206', 'AAINDEX207', 'AAINDEX208', 'AAINDEX209', 'AAINDEX210', 'AAINDEX211', 'AAINDEX212', 'AAINDEX213', 'AAINDEX214', 'AAINDEX215', 'AAINDEX216', 'AAINDEX217', 'AAINDEX218', 'AAINDEX219', 'AAINDEX220', 'AAINDEX221', 'AAINDEX222', 'AAINDEX223', 'AAINDEX224', 'AAINDEX225', 'AAINDEX226', 'AAINDEX227', 'AAINDEX228', 'AAINDEX229', 'AAINDEX230', 'AAINDEX231', 'AAINDEX232', 'AAINDEX233', 'AAINDEX234', 'AAINDEX235', 'AAINDEX236', 'AAINDEX237', 'AAINDEX238', 'AAINDEX239', 'AAINDEX240', 'AAINDEX241', 'AAINDEX242', 'AAINDEX243', 'AAINDEX244', 'AAINDEX245', 'AAINDEX246', 'AAINDEX247', 'AAINDEX248', 'AAINDEX249', 'AAINDEX250', 'AAINDEX251', 'AAINDEX252', 'AAINDEX253', 'AAINDEX254', 'AAINDEX255', 'AAINDEX256', 'AAINDEX257', 'AAINDEX258', 'AAINDEX259', 'AAINDEX260', 'AAINDEX261', 'AAINDEX262', 'AAINDEX263', 'AAINDEX264', 'AAINDEX265', 'AAINDEX266', 'AAINDEX267', 'AAINDEX268', 'AAINDEX269', 'AAINDEX270', 'AAINDEX271', 'AAINDEX272', 'AAINDEX273', 'AAINDEX274', 'AAINDEX275', 'AAINDEX276', 'AAINDEX277', 'AAINDEX278', 'AAINDEX279', 'AAINDEX280', 'AAINDEX281', 'AAINDEX282', 'AAINDEX283', 'AAINDEX284', 'AAINDEX285', 'AAINDEX286', 'AAINDEX287', 'AAINDEX288', 'AAINDEX289', 'AAINDEX290', 'AAINDEX291', 'AAINDEX292', 'AAINDEX293', 'AAINDEX294', 'AAINDEX295', 'AAINDEX296', 'AAINDEX297', 'AAINDEX298', 'AAINDEX299', 'AAINDEX300', 'AAINDEX301', 'AAINDEX302', 'AAINDEX303', 'AAINDEX304', 'AAINDEX305', 'AAINDEX306', 'AAINDEX307', 'AAINDEX308', 'AAINDEX309', 'AAINDEX310', 'AAINDEX311', 'AAINDEX312', 'AAINDEX313', 'AAINDEX314', 'AAINDEX315', 'AAINDEX316', 'AAINDEX317', 'AAINDEX318', 'AAINDEX319', 'AAINDEX320', 'AAINDEX321', 'AAINDEX322', 'AAINDEX323', 'AAINDEX324', 'AAINDEX325', 'AAINDEX326', 'AAINDEX327', 'AAINDEX328', 'AAINDEX329', 'AAINDEX330', 'AAINDEX331', 'AAINDEX332', 'AAINDEX333', 'AAINDEX334', 'AAINDEX335', 'AAINDEX336', 'AAINDEX337', 'AAINDEX338', 'AAINDEX339', 'AAINDEX340', 'AAINDEX341', 'AAINDEX342', 'AAINDEX343', 'AAINDEX344', 'AAINDEX345', 'AAINDEX346', 'AAINDEX347', 'AAINDEX348', 'AAINDEX349', 'AAINDEX350', 'AAINDEX351', 'AAINDEX352', 'AAINDEX353', 'AAINDEX354', 'AAINDEX355', 'AAINDEX356', 'AAINDEX357', 'AAINDEX358', 'AAINDEX359', 'AAINDEX360', 'AAINDEX361', 'AAINDEX362', 'AAINDEX363', 'AAINDEX364', 'AAINDEX365', 'AAINDEX366', 'AAINDEX367', 'AAINDEX368', 'AAINDEX369', 'AAINDEX370', 'AAINDEX371', 'AAINDEX372', 'AAINDEX373', 'AAINDEX374', 'AAINDEX375', 'AAINDEX376', 'AAINDEX377', 'AAINDEX378', 'AAINDEX379', 'AAINDEX380', 'AAINDEX381', 'AAINDEX382', 'AAINDEX383', 'AAINDEX384', 'AAINDEX385', 'AAINDEX386', 'AAINDEX387', 'AAINDEX388', 'AAINDEX389', 'AAINDEX390', 'AAINDEX391', 'AAINDEX392', 'AAINDEX393', 'AAINDEX394', 'AAINDEX395', 'AAINDEX396', 'AAINDEX397', 'AAINDEX398', 'AAINDEX399', 'AAINDEX400', 'AAINDEX401', 'AAINDEX402', 'AAINDEX403', 'AAINDEX404', 'AAINDEX405', 'AAINDEX406', 'AAINDEX407', 'AAINDEX408', 'AAINDEX409', 'AAINDEX410', 'AAINDEX411', 'AAINDEX412', 'AAINDEX413', 'AAINDEX414', 'AAINDEX415', 'AAINDEX416', 'AAINDEX417', 'AAINDEX418', 'AAINDEX419', 'AAINDEX420', 'AAINDEX421', 'AAINDEX422', 'AAINDEX423', 'AAINDEX424', 'AAINDEX425', 'AAINDEX426', 'AAINDEX427', 'AAINDEX428', 'AAINDEX429', 'AAINDEX430', 'AAINDEX431', 'AAINDEX432', 'AAINDEX433', 'AAINDEX434', 'AAINDEX435', 'AAINDEX436', 'AAINDEX437', 'AAINDEX438', 'AAINDEX439', 'AAINDEX440', 'AAINDEX441', 'AAINDEX442', 'AAINDEX443', 'AAINDEX444', 'AAINDEX445', 'AAINDEX446', 'AAINDEX447', 'AAINDEX448', 'AAINDEX449', 'AAINDEX450', 'AAINDEX451', 'AAINDEX452', 'AAINDEX453', 'AAINDEX454', 'AAINDEX455', 'AAINDEX456', 'AAINDEX457', 'AAINDEX458', 'AAINDEX459', 'AAINDEX460', 'AAINDEX461', 'AAINDEX462', 'AAINDEX463', 'AAINDEX464', 'AAINDEX465', 'AAINDEX466', 'AAINDEX467', 'AAINDEX468', 'AAINDEX469', 'AAINDEX470', 'AAINDEX471', 'AAINDEX472', 'AAINDEX473', 'AAINDEX474', 'AAINDEX475', 'AAINDEX476', 'AAINDEX477', 'AAINDEX478', 'AAINDEX479', 'AAINDEX480', 'AAINDEX481', 'AAINDEX482', 'AAINDEX483', 'AAINDEX484', 'AAINDEX485', 'AAINDEX486', 'AAINDEX487', 'AAINDEX488', 'AAINDEX489', 'AAINDEX490', 'AAINDEX491', 'AAINDEX492', 'AAINDEX493', 'AAINDEX494', 'AAINDEX495', 'AAINDEX496', 'AAINDEX497', 'AAINDEX498', 'AAINDEX499', 'AAINDEX500', 'AAINDEX501', 'AAINDEX502', 'AAINDEX503', 'AAINDEX504', 'AAINDEX505', 'AAINDEX506', 'AAINDEX507', 'AAINDEX508', 'AAINDEX509', 'AAINDEX510', 'AAINDEX511', 'AAINDEX512', 'AAINDEX513', 'AAINDEX514', 'AAINDEX515', 'AAINDEX516', 'AAINDEX517', 'AAINDEX518', 'AAINDEX519', 'AAINDEX520', 'AAINDEX521', 'AAINDEX522', 'AAINDEX523', 'AAINDEX524', 'AAINDEX525', 'AAINDEX526', 'AAINDEX527', 'AAINDEX528', 'AAINDEX529', 'AAINDEX530', 'AAINDEX531'],\n",
    "    'apaac': ['APAAC1', 'APAAC2', 'APAAC3', 'APAAC4', 'APAAC5', 'APAAC6', 'APAAC7', 'APAAC8', 'APAAC9', 'APAAC10', 'APAAC11', 'APAAC12', 'APAAC13', 'APAAC14', 'APAAC15', 'APAAC16', 'APAAC17', 'APAAC18', 'APAAC19', 'APAAC20', 'APAAC21', 'APAAC22'],\n",
    "    'ctdc': ['CTD1', 'CTD2', 'CTD3', 'CTD4', 'CTD5', 'CTD6', 'CTD7', 'CTD8', 'CTD9', 'CTD10', 'CTD11', 'CTD12', 'CTD13', 'CTD14', 'CTD15', 'CTD16', 'CTD17', 'CTD18', 'CTD19', 'CTD20', 'CTD21', 'CTD22', 'CTD23', 'CTD24', 'CTD25', 'CTD26', 'CTD27', 'CTD28', 'CTD29', 'CTD30', 'CTD31', 'CTD32', 'CTD33', 'CTD34', 'CTD35', 'CTD36', 'CTD37', 'CTD38', 'CTD39', 'CTD40', 'CTD41', 'CTD42', 'CTD43', 'CTD44', 'CTD45', 'CTD46', 'CTD47', 'CTD48', 'CTD49', 'CTD50', 'CTD51', 'CTD52', 'CTD53', 'CTD54', 'CTD55', 'CTD56', 'CTD57', 'CTD58', 'CTD59', 'CTD60', 'CTD61', 'CTD62', 'CTD63', 'CTD64', 'CTD65', 'CTD66', 'CTD67', 'CTD68', 'CTD69', 'CTD70', 'CTD71', 'CTD72', 'CTD73', 'CTD74', 'CTD75', 'CTD76', 'CTD77', 'CTD78', 'CTD79', 'CTD80', 'CTD81', 'CTD82', 'CTD83', 'CTD84', 'CTD85', 'CTD86', 'CTD87', 'CTD88', 'CTD89', 'CTD90', 'CTD91', 'CTD92', 'CTD93', 'CTD94', 'CTD95', 'CTD96', 'CTD97', 'CTD98', 'CTD99', 'CTD100', 'CTD101', 'CTD102', 'CTD103', 'CTD104', 'CTD105', 'CTD106', 'CTD107', 'CTD108', 'CTD109', 'CTD110', 'CTD111', 'CTD112', 'CTD113', 'CTD114', 'CTD115', 'CTD116', 'CTD117', 'CTD118', 'CTD119', 'CTD120', 'CTD121', 'CTD122', 'CTD123', 'CTD124', 'CTD125', 'CTD126', 'CTD127', 'CTD128', 'CTD129', 'CTD130', 'CTD131', 'CTD132', 'CTD133', 'CTD134', 'CTD135', 'CTD136', 'CTD137', 'CTD138', 'CTD139', 'CTD140', 'CTD141', 'CTD142', 'CTD143', 'CTD144', 'CTD145', 'CTD146', 'CTD147', 'CTD148', 'CTD149', 'CTD150', 'CTD151', 'CTD152', 'CTD153', 'CTD154', 'CTD155', 'CTD156', 'CTD157', 'CTD158', 'CTD159', 'CTD160', 'CTD161', 'CTD162', 'CTD163', 'CTD164', 'CTD165', 'CTD166', 'CTD167', 'CTD168', 'CTD169', 'CTD170', 'CTD171', 'CTD172', 'CTD173', 'CTD174', 'CTD175', 'CTD176', 'CTD177', 'CTD178', 'CTD179', 'CTD180', 'CTD181', 'CTD182', 'CTD183', 'CTD184', 'CTD185', 'CTD186', 'CTD187', 'CTD188', 'CTD189', 'CTD190', 'CTD191', 'CTD192', 'CTD193', 'CTD194', 'CTD195', 'CTD196', 'CTD197', 'CTD198', 'CTD199', 'CTD200', 'CTD201', 'CTD202', 'CTD203', 'CTD204', 'CTD205', 'CTD206', 'CTD207', 'CTD208', 'CTD209', 'CTD210', 'CTD211', 'CTD212', 'CTD213', 'CTD214', 'CTD215', 'CTD216', 'CTD217', 'CTD218', 'CTD219', 'CTD220', 'CTD221', 'CTD222', 'CTD223', 'CTD224', 'CTD225', 'CTD226', 'CTD227', 'CTD228', 'CTD229', 'CTD230', 'CTD231', 'CTD232', 'CTD233', 'CTD234', 'CTD235', 'CTD236', 'CTD237', 'CTD238', 'CTD239', 'CTD240', 'CTD241', 'CTD242', 'CTD243', 'CTD244', 'CTD245', 'CTD246', 'CTD247', 'CTD248', 'CTD249', 'CTD250', 'CTD251', 'CTD252', 'CTD253', 'CTD254', 'CTD255', 'CTD256', 'CTD257', 'CTD258', 'CTD259', 'CTD260', 'CTD261', 'CTD262', 'CTD263', 'CTD264', 'CTD265', 'CTD266', 'CTD267', 'CTD268', 'CTD269', 'CTD270', 'CTD271', 'CTD272', 'CTD273'],\n",
    "    'dpc': ['DPC1', 'DPC2', 'DPC3', 'DPC4', 'DPC5', 'DPC6', 'DPC7', 'DPC8', 'DPC9', 'DPC10', 'DPC11', 'DPC12', 'DPC13', 'DPC14', 'DPC15', 'DPC16', 'DPC17', 'DPC18', 'DPC19', 'DPC20', 'DPC21', 'DPC22', 'DPC23', 'DPC24', 'DPC25', 'DPC26', 'DPC27', 'DPC28', 'DPC29', 'DPC30', 'DPC31', 'DPC32', 'DPC33', 'DPC34', 'DPC35', 'DPC36', 'DPC37', 'DPC38', 'DPC39', 'DPC40', 'DPC41', 'DPC42', 'DPC43', 'DPC44', 'DPC45', 'DPC46', 'DPC47', 'DPC48', 'DPC49', 'DPC50', 'DPC51', 'DPC52', 'DPC53', 'DPC54', 'DPC55', 'DPC56', 'DPC57', 'DPC58', 'DPC59', 'DPC60', 'DPC61', 'DPC62', 'DPC63', 'DPC64', 'DPC65', 'DPC66', 'DPC67', 'DPC68', 'DPC69', 'DPC70', 'DPC71', 'DPC72', 'DPC73', 'DPC74', 'DPC75', 'DPC76', 'DPC77', 'DPC78', 'DPC79', 'DPC80', 'DPC81', 'DPC82', 'DPC83', 'DPC84', 'DPC85', 'DPC86', 'DPC87', 'DPC88', 'DPC89', 'DPC90', 'DPC91', 'DPC92', 'DPC93', 'DPC94', 'DPC95', 'DPC96', 'DPC97', 'DPC98', 'DPC99', 'DPC100', 'DPC101', 'DPC102', 'DPC103', 'DPC104', 'DPC105', 'DPC106', 'DPC107', 'DPC108', 'DPC109', 'DPC110', 'DPC111', 'DPC112', 'DPC113', 'DPC114', 'DPC115', 'DPC116', 'DPC117', 'DPC118', 'DPC119', 'DPC120', 'DPC121', 'DPC122', 'DPC123', 'DPC124', 'DPC125', 'DPC126', 'DPC127', 'DPC128', 'DPC129', 'DPC130', 'DPC131', 'DPC132', 'DPC133', 'DPC134', 'DPC135', 'DPC136', 'DPC137', 'DPC138', 'DPC139', 'DPC140', 'DPC141', 'DPC142', 'DPC143', 'DPC144', 'DPC145', 'DPC146', 'DPC147', 'DPC148', 'DPC149', 'DPC150', 'DPC151', 'DPC152', 'DPC153', 'DPC154', 'DPC155', 'DPC156', 'DPC157', 'DPC158', 'DPC159', 'DPC160', 'DPC161', 'DPC162', 'DPC163', 'DPC164', 'DPC165', 'DPC166', 'DPC167', 'DPC168', 'DPC169', 'DPC170', 'DPC171', 'DPC172', 'DPC173', 'DPC174', 'DPC175', 'DPC176', 'DPC177', 'DPC178', 'DPC179', 'DPC180', 'DPC181', 'DPC182', 'DPC183', 'DPC184', 'DPC185', 'DPC186', 'DPC187', 'DPC188', 'DPC189', 'DPC190', 'DPC191', 'DPC192', 'DPC193', 'DPC194', 'DPC195', 'DPC196', 'DPC197', 'DPC198', 'DPC199', 'DPC200', 'DPC201', 'DPC202', 'DPC203', 'DPC204', 'DPC205', 'DPC206', 'DPC207', 'DPC208', 'DPC209', 'DPC210', 'DPC211', 'DPC212', 'DPC213', 'DPC214', 'DPC215', 'DPC216', 'DPC217', 'DPC218', 'DPC219', 'DPC220', 'DPC221', 'DPC222', 'DPC223', 'DPC224', 'DPC225', 'DPC226', 'DPC227', 'DPC228', 'DPC229', 'DPC230', 'DPC231', 'DPC232', 'DPC233', 'DPC234', 'DPC235', 'DPC236', 'DPC237', 'DPC238', 'DPC239', 'DPC240', 'DPC241', 'DPC242', 'DPC243', 'DPC244', 'DPC245', 'DPC246', 'DPC247', 'DPC248', 'DPC249', 'DPC250', 'DPC251', 'DPC252', 'DPC253', 'DPC254', 'DPC255', 'DPC256', 'DPC257', 'DPC258', 'DPC259', 'DPC260', 'DPC261', 'DPC262', 'DPC263', 'DPC264', 'DPC265', 'DPC266', 'DPC267', 'DPC268', 'DPC269', 'DPC270', 'DPC271', 'DPC272', 'DPC273', 'DPC274', 'DPC275', 'DPC276', 'DPC277', 'DPC278', 'DPC279', 'DPC280', 'DPC281', 'DPC282', 'DPC283', 'DPC284', 'DPC285', 'DPC286', 'DPC287', 'DPC288', 'DPC289', 'DPC290', 'DPC291', 'DPC292', 'DPC293', 'DPC294', 'DPC295', 'DPC296', 'DPC297', 'DPC298', 'DPC299', 'DPC300', 'DPC301', 'DPC302', 'DPC303', 'DPC304', 'DPC305', 'DPC306', 'DPC307', 'DPC308', 'DPC309', 'DPC310', 'DPC311', 'DPC312', 'DPC313', 'DPC314', 'DPC315', 'DPC316', 'DPC317', 'DPC318', 'DPC319', 'DPC320', 'DPC321', 'DPC322', 'DPC323', 'DPC324', 'DPC325', 'DPC326', 'DPC327', 'DPC328', 'DPC329', 'DPC330', 'DPC331', 'DPC332', 'DPC333', 'DPC334', 'DPC335', 'DPC336', 'DPC337', 'DPC338', 'DPC339', 'DPC340', 'DPC341', 'DPC342', 'DPC343', 'DPC344', 'DPC345', 'DPC346', 'DPC347', 'DPC348', 'DPC349', 'DPC350', 'DPC351', 'DPC352', 'DPC353', 'DPC354', 'DPC355', 'DPC356', 'DPC357', 'DPC358', 'DPC359', 'DPC360', 'DPC361', 'DPC362', 'DPC363', 'DPC364', 'DPC365', 'DPC366', 'DPC367', 'DPC368', 'DPC369', 'DPC370', 'DPC371', 'DPC372', 'DPC373', 'DPC374', 'DPC375', 'DPC376', 'DPC377', 'DPC378', 'DPC379', 'DPC380', 'DPC381', 'DPC382', 'DPC383', 'DPC384', 'DPC385', 'DPC386', 'DPC387', 'DPC388', 'DPC389', 'DPC390', 'DPC391', 'DPC392', 'DPC393', 'DPC394', 'DPC395', 'DPC396', 'DPC397', 'DPC398', 'DPC399', 'DPC400'],\n",
    "    'paac': ['PAAC1', 'PAAC2', 'PAAC3', 'PAAC4', 'PAAC5', 'PAAC6', 'PAAC7', 'PAAC8', 'PAAC9', 'PAAC10', 'PAAC11', 'PAAC12', 'PAAC13', 'PAAC14', 'PAAC15', 'PAAC16', 'PAAC17', 'PAAC18', 'PAAC19', 'PAAC20', 'PAAC21'],\n",
    "    'racid': ['reducedACID1', 'reducedACID2', 'reducedACID3', 'reducedACID4', 'reducedACID5', 'reducedACID6', 'reducedACID7', 'reducedACID8', 'reducedACID9', 'reducedACID10', 'reducedACID11', 'reducedACID12', 'reducedACID13', 'reducedACID14', 'reducedACID15', 'reducedACID16', 'reducedACID17', 'reducedACID18', 'reducedACID19', 'reducedACID20', 'reducedACID21', 'reducedACID22', 'reducedACID23', 'reducedACID24', 'reducedACID25', 'reducedACID26', 'reducedACID27', 'reducedACID28', 'reducedACID29', 'reducedACID30', 'reducedACID31', 'reducedACID32'],\n",
    "    'rcharge': ['reducedCHARGE1', 'reducedCHARGE2', 'reducedCHARGE3', 'reducedCHARGE4', 'reducedCHARGE5', 'reducedCHARGE6', 'reducedCHARGE7', 'reducedCHARGE8', 'reducedCHARGE9', 'reducedCHARGE10', 'reducedCHARGE11', 'reducedCHARGE12', 'reducedCHARGE13', 'reducedCHARGE14', 'reducedCHARGE15', 'reducedCHARGE16', 'reducedCHARGE17', 'reducedCHARGE18', 'reducedCHARGE19', 'reducedCHARGE20', 'reducedCHARGE21', 'reducedCHARGE22', 'reducedCHARGE23', 'reducedCHARGE24', 'reducedCHARGE25', 'reducedCHARGE26', 'reducedCHARGE27', 'reducedCHARGE28', 'reducedCHARGE29', 'reducedCHARGE30', 'reducedCHARGE31', 'reducedCHARGE32'],\n",
    "    'rdhp': ['reducedDHP1', 'reducedDHP2', 'reducedDHP3', 'reducedDHP4', 'reducedDHP5', 'reducedDHP6', 'reducedDHP7', 'reducedDHP8', 'reducedDHP9', 'reducedDHP10', 'reducedDHP11', 'reducedDHP12', 'reducedDHP13', 'reducedDHP14', 'reducedDHP15', 'reducedDHP16', 'reducedDHP17', 'reducedDHP18', 'reducedDHP19', 'reducedDHP20', 'reducedDHP21', 'reducedDHP22', 'reducedDHP23', 'reducedDHP24', 'reducedDHP25', 'reducedDHP26', 'reducedDHP27', 'reducedDHP28', 'reducedDHP29', 'reducedDHP30', 'reducedDHP31', 'reducedDHP32', 'reducedDHP33', 'reducedDHP34', 'reducedDHP35', 'reducedDHP36', 'reducedDHP37', 'reducedDHP38', 'reducedDHP39', 'reducedDHP40'],\n",
    "    'rpolar': ['reducedPOLAR1', 'reducedPOLAR2', 'reducedPOLAR3', 'reducedPOLAR4', 'reducedPOLAR5', 'reducedPOLAR6', 'reducedPOLAR7', 'reducedPOLAR8', 'reducedPOLAR9', 'reducedPOLAR10', 'reducedPOLAR11', 'reducedPOLAR12', 'reducedPOLAR13', 'reducedPOLAR14', 'reducedPOLAR15', 'reducedPOLAR16', 'reducedPOLAR17', 'reducedPOLAR18', 'reducedPOLAR19', 'reducedPOLAR20', 'reducedPOLAR21', 'reducedPOLAR22', 'reducedPOLAR23', 'reducedPOLAR24', 'reducedPOLAR25', 'reducedPOLAR26', 'reducedPOLAR27', 'reducedPOLAR28', 'reducedPOLAR29', 'reducedPOLAR30', 'reducedPOLAR31', 'reducedPOLAR32', 'reducedPOLAR33', 'reducedPOLAR34', 'reducedPOLAR35', 'reducedPOLAR36', 'reducedPOLAR37', 'reducedPOLAR38', 'reducedPOLAR39', 'reducedPOLAR40', 'reducedPOLAR41', 'reducedPOLAR42', 'reducedPOLAR43', 'reducedPOLAR44', 'reducedPOLAR45', 'reducedPOLAR46', 'reducedPOLAR47', 'reducedPOLAR48', 'reducedPOLAR49', 'reducedPOLAR50'],\n",
    "    'rsecond': ['reducedSECOND1', 'reducedSECOND2', 'reducedSECOND3', 'reducedSECOND4', 'reducedSECOND5', 'reducedSECOND6', 'reducedSECOND7', 'reducedSECOND8', 'reducedSECOND9', 'reducedSECOND10', 'reducedSECOND11', 'reducedSECOND12', 'reducedSECOND13', 'reducedSECOND14', 'reducedSECOND15', 'reducedSECOND16', 'reducedSECOND17', 'reducedSECOND18', 'reducedSECOND19', 'reducedSECOND20', 'reducedSECOND21', 'reducedSECOND22', 'reducedSECOND23', 'reducedSECOND24', 'reducedSECOND25', 'reducedSECOND26', 'reducedSECOND27', 'reducedSECOND28', 'reducedSECOND29', 'reducedSECOND30', 'reducedSECOND31', 'reducedSECOND32']\n",
    "}\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'XGB': XGBClassifier(),\n",
    "    'ET': ExtraTreesClassifier(),\n",
    "    'ADA': AdaBoostClassifier(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NB': GaussianNB(),\n",
    "    'NN': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are already loaded DataFrames\n",
    "results_dict = {}\n",
    "\n",
    "# Train classifiers and predict probabilities for each descriptor\n",
    "for desc, columns in descriptor_groups.items():\n",
    "    # Extract columns corresponding to the current descriptor group\n",
    "    X_train_desc = X_train[columns]\n",
    "    X_test_desc = X_test[columns]\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train_desc, y_train)\n",
    "        probs = clf.predict_proba(X_test_desc)[:, 1]\n",
    "        # Save the probabilities in the results dictionary\n",
    "        results_dict[f'{desc}_{name}'] = probs\n",
    "\n",
    "# Create DataFrame for results\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df['Label'] = y_test.values\n",
    "\n",
    "# Show the first few rows of the results DataFrame\n",
    "#print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fadd1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:48.979838Z",
     "iopub.status.busy": "2024-09-20T06:48:48.979082Z",
     "iopub.status.idle": "2024-09-20T06:48:49.005086Z",
     "shell.execute_reply": "2024-09-20T06:48:49.004099Z"
    },
    "papermill": {
     "duration": 0.053241,
     "end_time": "2024-09-20T06:48:49.008208",
     "exception": false,
     "start_time": "2024-09-20T06:48:48.954967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Step 1: Load the pre-trained model\n",
    "# Load the saved XGBoost model\n",
    "model_path = '/kaggle/input/ga-xgb-xgb/xgboost_protein_classifier-3.pkl'\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Step 2: Load the unknown data from CSV (replace with your actual GitHub CSV URL or file path)\n",
    "unknown_data = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97942d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.036405Z",
     "iopub.status.busy": "2024-09-20T06:48:49.035959Z",
     "iopub.status.idle": "2024-09-20T06:48:49.048434Z",
     "shell.execute_reply": "2024-09-20T06:48:49.047361Z"
    },
    "papermill": {
     "duration": 0.028986,
     "end_time": "2024-09-20T06:48:49.051153",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.022167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming the CSV has the same features as the model was trained on, except the target variable\n",
    "# Step 3: Load the selected feature names used during training (if available)\n",
    "# Assuming you have saved the selected feature names used in training\n",
    "selected_feature_names_path = '/kaggle/input/ga-xgb-xgb/selected_feature_names.pkl'  # Path to your saved selected features\n",
    "selected_feature_names = joblib.load(selected_feature_names_path)  # Load the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7188558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.074007Z",
     "iopub.status.busy": "2024-09-20T06:48:49.073544Z",
     "iopub.status.idle": "2024-09-20T06:48:49.079992Z",
     "shell.execute_reply": "2024-09-20T06:48:49.078793Z"
    },
    "papermill": {
     "duration": 0.021078,
     "end_time": "2024-09-20T06:48:49.082770",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.061692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Preprocess the unknown data\n",
    "# Filter the unknown data to keep only the selected features\n",
    "X_unknown_raw = unknown_data[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae00e037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.105706Z",
     "iopub.status.busy": "2024-09-20T06:48:49.105097Z",
     "iopub.status.idle": "2024-09-20T06:48:49.119497Z",
     "shell.execute_reply": "2024-09-20T06:48:49.118425Z"
    },
    "papermill": {
     "duration": 0.029239,
     "end_time": "2024-09-20T06:48:49.122408",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.093169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5: Apply the same scaling as was used for the training data\n",
    "# First apply Min-Max scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_unknown_minmax = scaler_minmax.fit_transform(X_unknown_raw)\n",
    "\n",
    "# Then apply Standard scaling\n",
    "scaler_standard = StandardScaler()\n",
    "X_unknown = scaler_standard.fit_transform(X_unknown_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6887c085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.145324Z",
     "iopub.status.busy": "2024-09-20T06:48:49.144794Z",
     "iopub.status.idle": "2024-09-20T06:48:49.154316Z",
     "shell.execute_reply": "2024-09-20T06:48:49.153374Z"
    },
    "papermill": {
     "duration": 0.024195,
     "end_time": "2024-09-20T06:48:49.157142",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.132947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Make predictions with the pre-trained model\n",
    "predictions = model.predict(X_unknown)\n",
    "\n",
    "# Optional: Get prediction probabilities\n",
    "prediction_probabilities = model.predict_proba(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d10bd6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.181576Z",
     "iopub.status.busy": "2024-09-20T06:48:49.181067Z",
     "iopub.status.idle": "2024-09-20T06:48:49.211428Z",
     "shell.execute_reply": "2024-09-20T06:48:49.210130Z"
    },
    "papermill": {
     "duration": 0.046089,
     "end_time": "2024-09-20T06:48:49.215043",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.168954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     aac_LR  aac_RF   aac_SVM   aac_XGB  aac_ET   aac_ADA  aac_DT  aac_KNN  \\\n",
      "0  0.718674    0.59  0.350027  0.982722    0.58  0.522114     1.0      0.8   \n",
      "1  0.582850    0.58  0.331013  0.744372    0.52  0.523755     1.0      0.2   \n",
      "2  0.744403    0.56  0.333168  0.592360    0.40  0.336369     1.0      0.2   \n",
      "3  0.222189    0.47  0.346755  0.371299    0.41  0.326750     1.0      0.2   \n",
      "4  0.653151    0.49  0.439770  0.164047    0.43  0.504773     1.0      1.0   \n",
      "\n",
      "     aac_NB    aac_NN  ...  rsecond_XGB  rsecond_ET  rsecond_ADA  rsecond_DT  \\\n",
      "0  1.000000  0.974995  ...     0.949018        0.65     0.505667         0.0   \n",
      "1  0.999999  0.223667  ...     0.069219        0.40     0.491371         0.0   \n",
      "2  1.000000  0.261897  ...     0.270812        0.38     0.481435         0.0   \n",
      "3  0.030014  0.296908  ...     0.027681        0.33     0.487145         1.0   \n",
      "4  1.000000  0.315004  ...     0.528655        0.61     0.486149         0.0   \n",
      "\n",
      "   rsecond_KNN  rsecond_NB  rsecond_NN  Label  Prediction  \\\n",
      "0          1.0    1.000000    0.967068    1.0           0   \n",
      "1          0.0    1.000000    0.431378    1.0           0   \n",
      "2          0.2    0.999996    0.334296    1.0           1   \n",
      "3          0.2    0.723313    0.050077    1.0           0   \n",
      "4          0.8    0.995870    0.911015    1.0           0   \n",
      "\n",
      "   Prediction_Probability  \n",
      "0                0.811007  \n",
      "1                0.945215  \n",
      "2                0.543638  \n",
      "3                0.981778  \n",
      "4                0.749902  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Output the predictions\n",
    "# Adding predictions to the original dataframe for review\n",
    "unknown_data['Prediction'] = predictions\n",
    "unknown_data['Prediction_Probability'] = prediction_probabilities.max(axis=1)\n",
    "\n",
    "# Display the first few rows with predictions\n",
    "print(unknown_data.head())\n",
    "\n",
    "# Optional: Save the prediction results to a CSV file\n",
    "unknown_data.to_csv('predicted_anti_HIV_peptides.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce7f5bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T06:48:49.238276Z",
     "iopub.status.busy": "2024-09-20T06:48:49.237790Z",
     "iopub.status.idle": "2024-09-20T06:48:49.280554Z",
     "shell.execute_reply": "2024-09-20T06:48:49.279354Z"
    },
    "papermill": {
     "duration": 0.057294,
     "end_time": "2024-09-20T06:48:49.283074",
     "exception": false,
     "start_time": "2024-09-20T06:48:49.225780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aac_LR</th>\n",
       "      <th>aac_RF</th>\n",
       "      <th>aac_SVM</th>\n",
       "      <th>aac_XGB</th>\n",
       "      <th>aac_ET</th>\n",
       "      <th>aac_ADA</th>\n",
       "      <th>aac_DT</th>\n",
       "      <th>aac_KNN</th>\n",
       "      <th>aac_NB</th>\n",
       "      <th>aac_NN</th>\n",
       "      <th>...</th>\n",
       "      <th>rsecond_XGB</th>\n",
       "      <th>rsecond_ET</th>\n",
       "      <th>rsecond_ADA</th>\n",
       "      <th>rsecond_DT</th>\n",
       "      <th>rsecond_KNN</th>\n",
       "      <th>rsecond_NB</th>\n",
       "      <th>rsecond_NN</th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Prediction_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718674</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.350027</td>\n",
       "      <td>0.982722</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.522114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.974995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949018</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.505667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.582850</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>0.744372</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.523755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.999994e-01</td>\n",
       "      <td>0.223667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069219</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.491371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.744403</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.333168</td>\n",
       "      <td>0.592360</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.336369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.261897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270812</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.481435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.334296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222189</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.346755</td>\n",
       "      <td>0.371299</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.326750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.001356e-02</td>\n",
       "      <td>0.296908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.487145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.723313</td>\n",
       "      <td>0.050077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.653151</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.439770</td>\n",
       "      <td>0.164047</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.504773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>0.315004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528655</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.486149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.995870</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.749902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.329084</td>\n",
       "      <td>0.208410</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.327235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.708866e-08</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.470651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083529</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.299220</td>\n",
       "      <td>0.126354</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.317538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.905354e-01</td>\n",
       "      <td>0.021069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138857</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.311078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.424329</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.333220</td>\n",
       "      <td>0.690976</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.506956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.761835e-04</td>\n",
       "      <td>0.068490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.484172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.335888</td>\n",
       "      <td>0.840432</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.522632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.179147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171647</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.487231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.445292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.329354</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.503697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.885463e-01</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.501325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.219744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aac_LR  aac_RF   aac_SVM   aac_XGB  aac_ET   aac_ADA  aac_DT  aac_KNN  \\\n",
       "0  0.718674    0.59  0.350027  0.982722    0.58  0.522114     1.0      0.8   \n",
       "1  0.582850    0.58  0.331013  0.744372    0.52  0.523755     1.0      0.2   \n",
       "2  0.744403    0.56  0.333168  0.592360    0.40  0.336369     1.0      0.2   \n",
       "3  0.222189    0.47  0.346755  0.371299    0.41  0.326750     1.0      0.2   \n",
       "4  0.653151    0.49  0.439770  0.164047    0.43  0.504773     1.0      1.0   \n",
       "5  0.007041    0.38  0.329084  0.208410    0.20  0.327235     0.0      0.0   \n",
       "6  0.083529    0.37  0.299220  0.126354    0.30  0.317538     1.0      0.2   \n",
       "7  0.424329    0.54  0.333220  0.690976    0.35  0.506956     0.0      0.4   \n",
       "8  0.480176    0.46  0.335888  0.840432    0.53  0.522632     1.0      0.4   \n",
       "9  0.057694    0.45  0.329354  0.053977    0.27  0.503697     1.0      0.2   \n",
       "\n",
       "         aac_NB    aac_NN  ...  rsecond_XGB  rsecond_ET  rsecond_ADA  \\\n",
       "0  1.000000e+00  0.974995  ...     0.949018        0.65     0.505667   \n",
       "1  9.999994e-01  0.223667  ...     0.069219        0.40     0.491371   \n",
       "2  1.000000e+00  0.261897  ...     0.270812        0.38     0.481435   \n",
       "3  3.001356e-02  0.296908  ...     0.027681        0.33     0.487145   \n",
       "4  9.999998e-01  0.315004  ...     0.528655        0.61     0.486149   \n",
       "5  5.708866e-08  0.000089  ...     0.025554        0.29     0.470651   \n",
       "6  3.905354e-01  0.021069  ...     0.138857        0.37     0.311078   \n",
       "7  4.761835e-04  0.068490  ...     0.016408        0.30     0.484172   \n",
       "8  1.000000e+00  0.179147  ...     0.171647        0.40     0.487231   \n",
       "9  9.885463e-01  0.000690  ...     0.002978        0.37     0.501325   \n",
       "\n",
       "   rsecond_DT  rsecond_KNN  rsecond_NB  rsecond_NN  Label  Prediction  \\\n",
       "0         0.0          1.0    1.000000    0.967068    1.0           0   \n",
       "1         0.0          0.0    1.000000    0.431378    1.0           0   \n",
       "2         0.0          0.2    0.999996    0.334296    1.0           1   \n",
       "3         1.0          0.2    0.723313    0.050077    1.0           0   \n",
       "4         0.0          0.8    0.995870    0.911015    1.0           0   \n",
       "5         0.0          0.2    0.000010    0.000335    1.0           0   \n",
       "6         1.0          0.0    0.999268    0.055531    1.0           0   \n",
       "7         1.0          0.0    0.000047    0.003615    1.0           0   \n",
       "8         1.0          0.2    0.592108    0.445292    1.0           0   \n",
       "9         1.0          0.0    0.007319    0.219744    1.0           0   \n",
       "\n",
       "   Prediction_Probability  \n",
       "0                0.811007  \n",
       "1                0.945215  \n",
       "2                0.543638  \n",
       "3                0.981778  \n",
       "4                0.749902  \n",
       "5                0.990386  \n",
       "6                0.987713  \n",
       "7                0.995507  \n",
       "8                0.921922  \n",
       "9                0.896462  \n",
       "\n",
       "[10 rows x 123 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_data"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5714434,
     "sourceId": 9435743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 99.124791,
   "end_time": "2024-09-20T06:48:50.016831",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-20T06:47:10.892040",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
